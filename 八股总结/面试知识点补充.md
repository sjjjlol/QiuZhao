# MySql

## 1.数据库层面发生死锁怎么办？

事务 A、事务 B 交叉持有锁

```sql
-- 事务 A
BEGIN;
UPDATE orders SET amount = 500 WHERE id = 1; -- 锁住 `id = 1`
UPDATE orders SET amount = 300 WHERE id = 2; -- 等待 `id = 2`

-- 事务 B
BEGIN;
UPDATE orders SET amount = 400 WHERE id = 2; -- 锁住 `id = 2`
UPDATE orders SET amount = 600 WHERE id = 1; -- 等待 `id = 1`

```

解决方法：
保持固定的加锁顺序：事务 A 和 事务 B 都按 `先锁 T1 再锁 T2` 进行操作



## 2.Sharding-Sphere分库分表的数据源存在什么地方？

### 核心原理

- SQL 解析

  - ```sql
    SELECT * FROM user WHERE user_id = 123;
    ```

  - ```
    表名: user
    查询条件: user_id = 123
    ```

- 分库分表路由

  - ```sql
    databaseShardingAlgorithm: user_id % 2
    tableShardingAlgorithm: user_id % 4
    ```

  - ```
    user_id=123：
    
    数据库：user_db_1
    
    表：user_table_3
    ```

- SQL 改写

  - ```
    SELECT * FROM user_table_3 WHERE user_id = 123;
    ```

- SQL 执行

  - 并行执行 SQL，提高性能

- 结果合并

  - **如果 SQL 查询涉及多个分片，ShardingSphere 需要合并结果**, 举个例子

  - ```sql
    SELECT COUNT(*) FROM user;
    ```

  - ```sql
    COUNT(user_db_0.user_table_0) + COUNT(user_db_0.user_table_1) + COUNT(user_db_1.user_table_2) + COUNT(user_db_1.user_table_3)
    ```

### 数据源配置

```yaml
spring:
  shardingsphere:
    datasource:
      names: ds0, ds1  # 数据源名称
      ds0:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/user_db_0
        username: root
        password: 123456
      ds1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/user_db_1
        username: root
        password: 123456

```



### 分库分表场景下如何生成全局唯一主键？

> **分库分表之后，每张表只能看到“自己那一部分数据”，不能用自增主键。必须使用分布式主键生成方案。**

![image-20250403174521440](./面试知识点补充.assets/image-20250403174521440.png)



### 怎么保证雪花算法的唯一性？

雪花算法id

```
[ 1bit | 41bit时间戳 | 10bit机器+数据中心ID | 12bit序列号 ]
```

​	•	1 bit：最高位固定为 0（正数）

​	•	41 bit：当前**时间戳**（毫秒）— 可用约 69 年

​	•	10 bit：**机器 ID**（5 bit 机房ID + 5 bit 机器ID）— 最多支持 1024 台节点

​	•	12 bit：**每毫秒内的自增序列** — 支持每台机器每毫秒生成 4096 个 ID



**只要每台机器 ID 不冲突，时间有序，序列号在一个毫秒内不重复，就能全局唯一。**





## 3.索引中能不能有 NULL？NULL 与其他值比较会怎样？



![image-20250403174059063](./面试知识点补充.assets/image-20250403174059063.png)



> 索引中是可以包含 NULL 值的，普通索引和唯一索引都允许，只要主键不允许。

> 由于 SQL 中 NULL != NULL，所以多个 NULL 插入唯一索引不会冲突。

> 判断 NULL 不能用 = NULL，要用 IS NULL；否则可能导致查询失败、索引失效。



## 3. 为什么大厂的数据库隔离级别选择读已提交，而不是可重复读？

> **大厂一般选择 Read Committed（读已提交） 而非 Repeatable Read（可重复读），是为了在高并发高吞吐的业务下获得更优的性能与更少的锁竞争，同时通过“业务补偿 + 乐观锁 +缓存一致性控制”来保障数据正确性。**



### 1.  Repeatable Read 的代价是 更多的锁/Undo版本管理

- InnoDB 为了支持**可重复读**，要构建**多版本视图（MVCC）**
- 还要保证**事务中看到的数据不会变化** ➝ 导致：
  - 快照版本多
  - Undo 保留时间长
  - 行锁竞争激烈
  - 更容易出现锁等待/死锁

#### 怎么理解？

**Read Committed（RC）**

- 每次读取，都会创建**新的 ReadView**
- 所以只需要保留**最近一次更新前的旧版本**就够了
- 一旦被其他事务读取过，旧版本很快就**不需要保留**

所以整体来说：

- Undo log 使用少，生命周期短
- 系统回收快，内存压力小

**Repeatable Read（RR）**

- 一个事务在开始读取时，**创建一个固定的 ReadView**

- 在整个事务期间，这个 ReadView 都不会变

- 为了保证“事务中多次读取相同的数据行看到一样的值”

  → 所有 **更新后的版本都必须保留直到这个事务结束**

**举个例子（RR下容易出问题）**

假设有一个长事务 A：

```sql
-- 事务A
BEGIN;
SELECT * FROM product WHERE id = 1; -- 创建 ReadView
... 逻辑执行很久没提交 ...
```

这时有无数个短事务 B、C、D 不断更新 product.id=1，都会生成新的版本。

> 但由于事务 A 没提交，ReadView 一直没释放，InnoDB **不能清理 Undo Log**，需要保留这些旧版本，以防 A 再次读时要回滚到旧值。

**这就会导致：**

- undo log **持续积压**（影响 数据库的GC）
- **版本链变长**，每次访问要遍历更多版本节点
- insert buffer、purge 线程压力增大



#### InnoDB 是如何“GC” Undo Log 的？

**1.  每当有写操作（如 UPDATE/DELETE）发生：**

- InnoDB 会生成一份 Undo Log（旧版本）
- 这些版本会挂在记录后面的**版本链（Version Chain）**上

**2. Undo Log 的清理依赖 所有事务的 ReadView**

- 如果还有某个事务的 ReadView **早于**某条 Undo 的版本 ➝ **这条 Undo 就不能删！**
- 直到所有活跃事务都不再依赖它，它才会被清理





### 2.  Read Committed 更适合 高并发 场景

- Read Committed 每次查询都看到 **已提交版本**
- 查询压力小，行锁释放早，**不会阻塞其他事务**
- 高并发下性能明显优于 RR，尤其在“读多写多”场景



###  3.  大厂大量使用 乐观锁 + 唯一索引约束 + 分布式事务补偿

> 大厂在使用 Read Committed 隔离级别的前提下，**必须用业务逻辑手段**，来保证“最终一致”甚至“强一致”的效果。

```
乐观锁 + 唯一索引约束 + 分布式事务补偿
```



#### **乐观锁机制（Version / update_time 字段）**

目的： 防止**并发更新时覆盖别人的改动（Lost Update 问题）**

例子：

```sql
UPDATE product
SET stock = stock - 1, version = version + 1
WHERE id = 100 AND version = 8;
```



#### **唯一索引约束（保证天然幂等）**

目的：防止**同一业务主键数据被重复写入**

例子：

- 发券接口：避免发两张券
- 支付记录写入：同一个 order_id 只允许一条支付记录

```sql
CREATE UNIQUE INDEX uk_user_coupon ON t_user_coupon(user_id, coupon_template_id);
```

```java
try {
    insertCoupon(userId, templateId); // 有唯一索引
} catch (DuplicateKeyException e) {
    // 幂等处理，忽略/补偿
}
```



#### **分布式事务补偿（最终一致性）**

> 当不能使用强事务时（跨服务、跨库），就靠**补偿机制** + 幂等性 + MQ 保障最终一致。

| **模式**          | **描述**                                    |
| ----------------- | ------------------------------------------- |
| 本地消息表        | 写业务表和消息表在同一事务中，MQ 再异步投递 |
| RocketMQ 事务消息 | 半消息发送 + 回查确认机制                   |
| TCC 模式          | Try/Confirm/Cancel 三阶段显式控制           |
| 异步补偿任务      | 扫描状态失败的记录，补偿重试                |

例子：

- 用户支付后系统插入支付记录（status = pending）
- MQ 投递支付成功事件
- 如果消息未成功发出 ➝ 补偿任务扫描本地表补发



### 4.  大厂普遍采用微服务 + 分库分表架构

> Repeatable Read 在**分布式数据库中跨库事务难以保证一致性**

- 一致性保证由应用层负责（分布式锁、TCC、幂等等）
- 数据库只负责基础的读写能力 + 最基础的隔离



# JUC

## 1.用线程池去多线程地解析一个很大的文件，如何操作？如何选择阻塞队列？

**问题分析**：

1. **文件很大，不能一次性加载到内存**。
2. **需要使用线程池，并发解析文件**，提高处理效率。
3. 如何选择合适的阻塞队列？
   - 任务队列需要考虑**生产者-消费者模型**。
   - 任务不能堆积太多，否则会造成内存溢出。

**SynchronousQueue 带来的好处**

**`SynchronousQueue` 不存任务，必须立刻消费，防止任务堆积**。

**如果消费者消费速度慢，生产者会阻塞，防止内存占用过高**。

**适用于“实时消费，不能积压”的场景，如日志解析、在线流处理。**



1. 生产者线程
   - 逐行读取大文件，将行数据提交到 `SynchronousQueue`。
   - **如果消费者处理慢，生产者会阻塞，防止过多任务积压**。
2. 消费者线程（线程池）
   - 直接从 `SynchronousQueue` 获取任务，**消费完成才能继续生产**。
   - 确保消费者能及时处理任务，避免积压。

如何保证文件解析高效？

**使用 `BufferedReader` 逐行读取文件，避免一次性加载**。

**使用 `SynchronousQueue` 控制任务流，避免积压**。

**线程池 `maximumPoolSize` > `corePoolSize`，让消费者根据负载自动扩展**。

**消费者进行** **异步批量处理，提高吞吐量**（如 Kafka/数据库写入）。



## 2.如果线程池嵌套线程池，可能会有什么问题？

> 线程池嵌套线程池可能导致任务被**死锁**卡住或**线程资源耗尽**，最终引发“线程饥饿”或“任务阻塞”的问题。

```java
ExecutorService pool = Executors.newFixedThreadPool(1);

Runnable outerTask = () -> {
    System.out.println("外层任务启动：" + Thread.currentThread().getName());

    Future<String> future = pool.submit(() -> {
        System.out.println("内层任务执行：" + Thread.currentThread().getName());
        return "inner done";
    });

    try {
        String result = future.get(); // ❗同步等待，当前线程卡住了
        System.out.println("结果：" + result);
    } catch (Exception e) {
        e.printStackTrace();
    }
};

pool.submit(outerTask);
```



# Redis

## 1.脑裂问题

![image-20250327154046837](./面试知识点补充.assets/image-20250327154046837.png)

![image-20250327154250478](./面试知识点补充.assets/image-20250327154250478.png)

### 脑裂带来的危害

![image-20250327154336466](./面试知识点补充.assets/image-20250327154336466.png)

### 解决方案

![image-20250327154502119](./面试知识点补充.assets/image-20250327154502119.png)



## 2.redis分布式锁和redisson分布式锁的区别？

Redis 分布式锁：使用 `SET NX EX`

**存在的问题**

1️⃣ **锁过期问题**：业务未完成，锁已自动过期，被其他线程抢占。
 2️⃣ **非可重入问题**：同一线程再次获取锁会失败，导致死锁。
 3️⃣ **非公平锁**：多个线程竞争时，可能某个线程一直抢不到锁。
 4️⃣ **Redis 主从复制延迟问题**：如果锁写入主节点，但还未同步到从节点，主节点宕机，可能导致**多个线程获取到相同的锁**（即锁丢失）。



Redisson 实现分布式锁

### **Redisson 优势**

1️⃣ **可重入锁**（同一线程可多次获取，不会死锁）。hash表实现
 2️⃣ **自动续期**（默认 `30s` 过期，且会**自动续期**，不会因业务执行时间过长导致锁提前释放）。独立的看门狗线程实现



## 3.假如数据库更新，删除了几个数据，布隆过滤器怎么处理？

### 为什么普通布隆过滤器不能直接删除数据？

###### 布隆过滤器使用 **多个哈希函数** 将 **一个 key 映射到多个 bit 位**

- **不能删除的原因**：
  - **多个 key 可能共用相同 bit 位**（哈希冲突）。
  - **如果直接把 bit 置 `0`，可能影响其他 key**（误删）。
  - **布隆过滤器本质上是单向 `set` 操作，无法反向 `unset`**。

### 解决方案

#### 重建布隆过滤器

 **适用场景**

- **数据删除量较大，布隆过滤器误判率较高**。
- **数据库支持批量查询，允许重新构建 Bloom Filter**。

**周期性重新构建布隆过滤器**（如每天、每周）。

**重新遍历数据库，插入最新的数据集合**



#### 使用计数布隆过滤器

原理：

- 计数布隆过滤器（CBF）**用整数数组替代 bit 数组**：

- **数据新增**：多个哈希函数对应的位置 `+1`。
- **数据删除**：多个哈希函数对应的位置 `-1`（如果 `count = 0`，表示删除）。

缺点：

**占用内存更大**（比普通 Bloom Filter 多 4~8 倍）。

**仍然可能出现误判（如果 `counter` 不准确）**。



## 4.redis的网络IO模型为什么由单线程的多路复用变成了多线程？ 有什么好处？

因为：

**❗ Redis 的“单线程”优势在** **IO密集场景下遇到瓶颈**

- 在高并发场景中，**网络读写占据了大量 CPU**；
- 主线程必须：处理命令 + recv(socket) + send(response)，**这些 IO 操作是阻塞的**；
- 即使命令处理很快，**线程也被 IO 拖慢**，成了性能瓶颈。

> ✅Redis是 **“单次请求非常快，但高并发场景下 IO 压力极大”的 IO 密集型系统**

| **好处**             | **说明**                                                   |
| -------------------- | ---------------------------------------------------------- |
| ✅ 利用多核 CPU       | 读写 IO 交给多个线程，**避免主线程被 IO 阻塞**             |
| ✅ 提高吞吐量         | 在高并发场景下，QPS 提升显著（尤其是大数据包）             |
| ✅ 保持命令处理单线程 | 依然避免加锁，保持原有高并发一致性优势                     |
| ✅ 向后兼容           | 默认关闭 IO 多线程，向前兼容性强，可逐步迁移               |
| ✅ 精细控制           | 可以配置线程数量，如 io-threads 4、io-threads-do-reads yes |



### 在CPU核数多的情况下， 多线程是否一定优与多路复用？

#### **多线程 vs 多路复用**

| **对比项** | **多线程**                            | **IO 多路复用（select/poll/epoll）** |
| ---------- | ------------------------------------- | ------------------------------------ |
| 本质       | 开多个线程，每个线程处理一个/多个任务 | 单线程监听多个 IO FD                 |
| 优点       | 真并发、适合 CPU 密集任务             | 开销小、线程少、适合 IO 密集任务     |
| 关键点     | 多核下能并行，吞吐高                  | 单线程低资源占用，但有上下文切换限制 |



#### **✅ 情况1：任务是 CPU 密集型**

> 比如图像渲染、视频压缩、矩阵乘法、深度学习推理…

✅ 多线程更优

- 多核 CPU 可以真正并行执行多个线程；
- 合理使用线程池可以发挥最大并行计算性能；
- 多路复用没意义（它是为 IO 等待设计的）；



------



#### **✅ 情况2：任务是 IO 密集型（如 Redis、网关、代理服务器）**

> 比如网络连接多，IO等待多，单次计算极快

🎯 多路复用通常更优（尤其连接数非常多时）

- 多线程会带来线程上下文切换（CPU cache miss + 调度成本）；
- 多路复用（如 epoll）可用一个线程处理成千上万个连接；
- 多线程适合小并发 + 长连接，但不一定比 epoll 更高效；
- Redis 就是经典的“单线程 + epoll”模型，性能极高；



------



#### **✅ 情况3：IO密集 + 数据处理也有点重（混合型）**

比如：

- 网络服务 + 请求还需解析 JSON、压缩图片等
- 消息队列系统 + 消息解码处理

此时：

✅ 多线程 + IO 多路复用结合 是最佳选择！

- 如：Redis 6 的 **“多线程处理 IO + 主线程处理命令”**；
- Netty：**主线程 epoll accept，子线程多线程处理业务**



### 多线程是否总能用满 CPU？

不一定：

- IO 阻塞、线程上下文切换、锁竞争、内存访问延迟等都可能导致“CPU 看起来很多线程，实际跑不满”；
- 使用多线程时一定要考虑：是否有 **共享资源？是否存在竞争？是否是真并行还是假并发？**



# RocketMQ

## 1.RocketMQ的事务？

### **为什么需要 RocketMQ 的事务消息？**

在优惠券秒杀中，我们通常：

1. Redis 成功扣减库存；
2. **异步发送 MQ 消息通知消费者写入数据库。**

> 这中间就有问题了：如果 Redis 扣减成功了，但 MQ 发送失败？或者 MQ 成功了但消费者写入数据库失败了？

**RocketMQ 的事务消息能做什么？**

RocketMQ 事务消息可以把 **本地事务执行 和 消息的发送状态 强一致绑定起来**，避免“扣库存成功但数据库写入失败”或“反之”这种状态。



### **RocketMQ 事务消息的原理机制**

RocketMQ 事务消息基于**两阶段提交协议（Two-Phase Commit, 2PC）**设计：

事务消息有三个状态：

| **状态**         | **含义**                            |
| ---------------- | ----------------------------------- |
| COMMIT_MESSAGE   | 提交事务，消费者可见                |
| ROLLBACK_MESSAGE | 回滚事务，消息丢弃                  |
| UNKNOW           | 不确定状态，RocketMQ 将回查本地事务 |



### **两阶段执行流程**

**👉 第一阶段：**

**发送 Half 消息（Prepare 消息）**

- 发送方调用 sendMessageInTransaction() 方法
- RocketMQ 会把这条消息存入 “事务消息专用队列”，但**消费者此时不可见**



**👉 第二阶段：**

**执行本地事务**

- 回调执行器 executeLocalTransaction() 被触发，你在这一步完成业务操作（如写数据库）



**👉 第三阶段：**

**根据本地事务结果执行 COMMIT 或 ROLLBACK**

- 如果事务执行成功，调用 transactionExecuter.commit() → 该消息对消费者可见
- 如果失败，则调用 rollback() → 消息被丢弃



 **如果消息生产者崩溃，RocketMQ 会如何处理？**

- RocketMQ 会定时发起**事务状态回查请求（Check）**，调用生产者本地的 checkLocalTransaction() 方法确认事务结果
- 开发者需实现这个接口，并返回事务状态



### **实际应用：下单扣库存 + 支付订单创建**

> **目标：既要扣 Redis 库存，又要写数据库领券记录，且要保证一致性。**

**背景需求**

```
用户点击「立即购买」，需要：
	•	A. 在本地系统中创建订单（写入数据库）
	•	B. 通知库存中心，扣减库存（通过消息）
```

**问题**

```
如果我们先写库，再发消息，可能出现写库成功但发消息失败；
如果先发消息，再写库，也存在写入失败但消息已发出去的问题。
```

**使用事务消息的目标**

```
只要订单创建成功，才能通知库存系统扣减库存；
如果订单创建失败，就不应该扣库存。
```

执行流程图

```
用户请求下单
     ↓
sendMessageInTransaction("扣库存消息")
     ↓
↓Prepare消息存入MQ（消费者不可见）
↓
回调本地 executeLocalTransaction() → 创建订单写库
     ↓
写库成功         写库失败
↓                    ↓
COMMIT        ROLLBACK
消息可见        消息丢弃
↓
库存系统消费者 → 扣减库存

如果生产者崩溃，RocketMQ 会触发 checkLocalTransaction() 回查
```

生产者代码

```java
// 执行本地事务
public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
    Order order = parseOrder(msg);
    boolean success = orderService.createOrder(order);
    return success ? COMMIT_MESSAGE : ROLLBACK_MESSAGE;
}

// 回查事务状态
public LocalTransactionState checkLocalTransaction(Message msg) {
    String orderId = msg.getKeys();
    if (orderService.isOrderExist(orderId)) {
        return COMMIT_MESSAGE;
    } else {
        return ROLLBACK_MESSAGE;
    }
}
```

总结

> **RocketMQ 事务消息是通过“发送半消息 + 回调本地事务 + 状态回查”机制，实现分布式操作与消息发送之间的强一致性保障。**

# JVM

## 1.JVM 最多能占系统多大内存？

理论上，对于64位系统，单个进程内存的最大寻址空间为2的64次方，非常大了，基本可以当作没有限制，所以-Xmx的最大值可以认为是无限大。

实际上，JVM 不能超过系统的**总物理内存（RAM）**，在 Linux 系统上，建议 JVM 使用物理内存的 80% 以下；

若超出了，如果启用了交换空间（swap 或 pagefile），JVM 可能会使用**物理内存 + swap** 作为运行时的可用内存

# 操作系统

## 1.系统最大内存指的是什么？

64位操作系统，理论寻址空间 **16EB（2^64）**，但受限于 RAM 和 Swap。

**系统最大内存** = 物理内存（RAM） + **虚拟内存**（Swap/Pagefile）（虚拟内存通常建议 Swap 大小 ≈ 物理内存）



## 2.虚存理论最大值是什么？

虚拟内存最大值理论上是**寻址空间**的大小。

64位操作系统，理论寻址空间 **16EB（2^64）**



## 3.协程了解吗？介绍一下，协程里面用 ThreadLocal 会有问题吗？

**协程（Coroutine）** 是一种比线程（Thread）更**轻量级**的并发执行单元。协程 由**用户态**调度，切换成本低（只需保存和恢复寄存器、栈等）

**协程中使用 `ThreadLocal` 可能会导致意外行为**，因为 `ThreadLocal` 绑定的是 **物理线程**，而协程在**多个物理线程上调度**时，`ThreadLocal` 可能无法正确传递。

比如，一个协程 **起初运行在 A 线程**，然后因挂起切换到 **B 线程** 继续执行，原来存储在 `ThreadLocal` 中的变量无法自动传递到新线程

解决方案：使用**TransmittableThreadLocal**，适用于 Java 线程池/虚拟线程



## 4.多线程和异步IO的对比

### 多线程方案

![img](https://ask.qcloudimg.com/http-save/yehe-1161110/c1541843uc.jpeg)

**每个请求由一个独立线程处理**，使用线程池控制线程数量

多线程的适用范围则是那种需要**长时间CPU**运算的场合，例如耗时较长的图形处理和算法执行。

但是往往由于使用线程编程的简单和符合习惯，所以很多朋友往往会使用多线程来执行耗时较长的I/O操作。



```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class MultiThreadExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(5); // 线程池大小 5

        for (int i = 0; i < 10; i++) {
            int taskId = i;
            executor.execute(() -> {
                System.out.println("线程 " + Thread.currentThread().getName() + " 处理任务 " + taskId);
                try { Thread.sleep(1000); } catch (InterruptedException ignored) { }
            });
        }

        executor.shutdown(); // 关闭线程池
    }
}

```



### 异步IO方案

![img](https://ask.qcloudimg.com/http-save/yehe-1161110/7g4kckddvp.jpeg)

**使用 `CompletableFuture` 或 `Netty` 进行异步非阻塞 IO**。

当需要执行**I/O操作**时，使用**异步**操作比使用**多线程+同步I/O**操作更合适。I/O操作不仅包括了直接的文件、网络的读写，还包括数据库操作、Web Service、HttpRequest以及.Net Remoting等跨进程的调用。

```java
import java.util.concurrent.CompletableFuture;

public class AsyncIOExample {
    public static void main(String[] args) {
        for (int i = 0; i < 10; i++) {
            int taskId = i;
            CompletableFuture.runAsync(() -> {
                System.out.println("线程 " + Thread.currentThread().getName() + " 异步处理任务 " + taskId);
                try { Thread.sleep(1000); } catch (InterruptedException ignored) { }
            });
        }

        try { Thread.sleep(2000); } catch (InterruptedException ignored) { } // 等待任务完成
    }
}

```



### 多线程和异步的区别

多线程是关于功能的并发执行。而异步编程是关于函数之间的非阻塞执行，我们可以将异步应用于单线程或多线程当中。

因此，**多线程只是异步编程的一种实现形式**。

比如，你和你的朋友决定一起做一顿午餐。“异步”就是你对朋友说：“你去商店买意大利面，回来的时候告诉我一声，然后一起做午餐。在你买意大利面的同时，我去准备番茄酱和饮料。”

而“线程”是：“你烧水，我加热番茄酱。当水烧开了，告诉我，我把意大利放进去。当番茄酱热了，你可以把奶酪添加进去。当两者都完成了，就可以坐下来一起吃晚餐。”在线程的示例中，我们可以看到“When，Do”的事件顺序，而这些顺序代表着每个人（线程）的指令集集合的顺序。

上述示例可以看出，多线程是与具体的执行者相关的，而异步是与任务相关的。

多线程是程序设计的逻辑层概念，它是进程中并发运行的一段代码，可以实现线程间的切换执行。

异步和同步是相对的，异步就是彼此独立，在等待某事件的过程中继续做自己的事，不需要等待这一事件完成后再工作。

多线程就是实现异步的一个方式。异步是让调用方法的主线程不需要同步等待另一线程的完成，从而可以让主线程干其它的事情。

所以本质上，异步和多线程并不是一个同等关系，**异步是最终目的，多线程只是实现异步的一种手段**。



### 如何选择

面对多线程和异步，我们该如何选择呢？其实，通常情况下选择的依据是主要取决于性能。

那么，同步/异步与单线程/多线程之间的所有组合，哪种模型表现更好？

简而言之，对于具有大量I/O操作和不同计算的大规模应用程序，使用异步多线程有利于充分利用计算资源，并且能够照顾到非阻塞函数。这也是所有操作系统所采用的线程模型。

编写异步操作的复杂程度较高，程序主要使用回调方式进行处理，与正常的思维方式有些出入，而且难以调试。而多线程的使用（滥用）会给系统带来上下文切换的额外负担，并且线程间的共享变量可能造成死锁。

因此在实现这两种模式时，往往需要处理资源竞争、死锁、共享资源和回调事件等问题。



## 5. 什么是线程饥饿

> **线程饥饿（Thread Starvation）是指某些线程长时间无法获得 CPU 或其他资源，一直处于就绪态，导致迟迟不能执行或完成任务。**

> 常见原因包括高优先级线程长期占用 CPU、调度器不公平、资源独占等



## 6.静态库和动态库

> 静态库是在**编译时**被打包进可执行文件中的代码库，最终生成的程序文件中包含了库的全部代码；.lib（Windows）
>
> 动态库是在**运行时**才被加载进内存的**共享代码库**。.dll（Windows）

> 静态库体积大、更新麻烦但运行独立；动态库体积小、易于维护，多个程序还能共享同一份内存，是现代操作系统下更常见的库加载方式。



## 二维数组是行优先还是列优先遍历效率高

**二维数组是行优先遍历效率更高**，这是因为**底层内存布局是按“行优先”方式存储的**

为什么？

- **内存布局**
  - **每一行在内存中是连续存储的**，而不同的行彼此之间不是连续的
- **CPU 缓存友好性**
  - **行优先：** 每次访问都在同一行，访问的是连续内存，**CPU 会将整个缓存行（cache line）加载进来，命中率高**
  - **列优先：** 每次跨行，访问的是不同数组对象，**CPU 每次都要加载新的地址，缓存命中率低，性能差**。



## 线程池中线程正在执行网络IO,我把线程终止了，这些网络IO会发生什么？

> 如果线程正在执行**阻塞 IO**（如 socket.read），直接通过 Thread.interrupt() 并不能中断 IO 操作，线程仍会被挂起。因为底层 socket 是由 native 实现，不响应 Java 中断标志。若想安全终止这类线程，通常的做法是在线程外部关闭对应的 socket，这样 read/write 方法会抛出异常从而退出阻塞状态，线程即可结束。这种方式比 Thread.stop 更安全、可控，也不会造成资源泄露。

> 和传统阻塞 IO 不同，Java **NIO** 是非阻塞的，并基于 Selector 进行多路复用。当线程阻塞在 Selector.select() 时，可以通过调用 selector.wakeup() 方法唤醒阻塞线程，这是一种线程安全的中断机制。相比传统 IO 需要关闭 socket 才能中断，NIO 提供了更灵活、更优雅的中断方式。因此在使用 NIO 时，可以安全地中断线程并释放资源。



## Fork/Join的底层

### 什么是Fork Join

ForkJoinPool 是 Java 7 引入的并行计算框架，用于将**一个大任务拆分成多个小任务**并行处理，最终再合并结果。

它基于 **“分而治之 + 工作窃取（work stealing）”** 的思想构建，是 Java 中非常高效的并行执行机制。



### ForkJoinPool 的底层核心机制

**1.** **每个线程维护一个双端队列（Deque）**

- 每个 ForkJoinWorkerThread 拥有自己的任务队列；
- 新提交的子任务默认放入线程自己队列的 **尾部（push）**。



**2.** **工作窃取机制（Work Stealing）**

- 如果一个线程空闲，它会从**其他线程的任务队列头部（pop）**偷一个任务执行；
- 这样可以**最大化 CPU 利用率，避免线程空转**；
- 窃取是线程安全的，通过 Unsafe + CAS 操作。



**3.** **轻量级任务调度**

- 使用的是 ForkJoinTask，比传统 Thread 和 Runnable 更轻量；
- 支持递归拆分、任务合并（fork/join）。



```
main线程:
    ↓ fork()
    ↓              ┌───────── Thread A (有任务) ─────────┐
主任务 → 子任务1 → │ push to 队尾                       │
         子任务2 → │ push to 队尾                       │
         子任务3 → └────────────────────────────────────┘

另一个线程 B 空闲：
    ↓ 从线程 A 的队列头 pop（即“偷任务”）

所有子任务完成：
    ↓ join() 合并结果
```



## 什么是文件描述符

> **文件描述符是操作系统用于表示“打开文件/资源”的一个整数句柄**，用于标识你当前进程打开的文件、Socket、管道等资源。

比如你打开一个文件：

```java
FileInputStream fis = new FileInputStream("test.txt");
```

底层实际上是操作系统返回了一个**整型 fd，比如 5**，之后你对这个 fis 的读取/写入，其实底层是 read(5, ...)、write(5, ...)。



## 讲一下kill命令从按回车到结束的整个过程

### 具体流程

#### 1.用户输入 kill 命令



#### 2.kill 命令调用系统调用 kill(pid, sig)

- kill() 并不是杀死进程的动作，而是**请求内核向目标进程发送信号**；
- 默认发送的是 SIGTERM（终止信号）



#### 3.进入内核态，执行系统调用 sys_kill()

- **检查目标进程是否存在**；

- **检查当前用户是否有权限向该进程发信号**（通常要求是相同用户）；

- **将信号 SIGTERM 标记到目标进程的 signal pending 集合中**（位图结构）；

- **返回到用户态，kill 命令结束**。



#### 4.目标进程下次被调度时收到信号

**操作系统调度目标进程**时，会检查其 signal pending：

- 如果发现 SIGTERM 在队列中，就会执行信号处理；
- 每个信号都有默认处理动作，SIGTERM 的默认动作是：**终止进程**。

#### 5.目标进程处理信号并退出

- 进程终止后，内核会**清理其资源**（关闭文件描述符、释放内存）；
- 给**父进程**发送 SIGCHLD 通知子进程退出（便于 wait()）；
- 进程状态变为 **ZOMBIE**，直到父进程回收。



## epoll

### epoll 为什么使用红黑树？

在 Linux 内核中，epoll 使用 **红黑树（rb-tree）来管理所有被监听的文件描述符（FD）**。

- 当你执行 epoll_ctl(EPOLL_CTL_ADD, fd, ...) 注册一个监听 FD；
- 内核会把这个 FD 加入一个红黑树中；
- 后续修改/删除时，也是在红黑树中查找该 FD。

| **原因**       | **说明**                                                     |
| -------------- | ------------------------------------------------------------ |
| ✅ 快速查找     | 红黑树是自平衡二叉搜索树，查找复杂度 O(logN)，适合大量 FD 的快速增删改查 |
| ✅ 高性能       | 比线性表、链表查找快，适合大量连接（比如 10w 连接场景）      |
| ✅ 内核实现现成 | Linux 内核已广泛使用红黑树结构（如进程调度、虚拟内存管理等） |
| ✅ 可替换性好   | 红黑树相比哈希表更具可控性，遍历有序，不依赖哈希函数冲突处理 |



### epoll 中红黑树是如何排序的？

红黑树中的节点，是以 **文件描述符（FD）这个整数值为 key 进行排序的**。

- epoll 内核红黑树中，节点的 key 是 fd；
- 插入时以 fd 为键插入到红黑树中；
- 这样可以保证快速通过 fd 找到对应的监听项。



## 讲讲cpu的三级缓存

### 什么是 CPU 缓存？

> CPU 缓存（Cache）是介于 CPU 和主内存（RAM）之间的高速缓存，用来加快数据读取速度，**弥补 CPU 运算速度远快于内存访问速度的差距**。



### 三级缓存的作用？

| **缓存级别** | **用途**                                         |
| ------------ | ------------------------------------------------ |
| L1           | 存储当前核心正在执行的指令、数据，命中率最高     |
| L2           | 当前核心数据的“二级缓冲”                         |
| L3           | 所有核心**共享缓存**，用于核心之间通信或数据协作 |

缓存的主要目的是提升 CPU 执行效率，**避免频繁访问慢速内存**（RAM）

```
CPU 读取变量 → 是否在 L1？是：返回
             ↓
             否 → 是否在 L2？是：拷贝到 L1
                  ↓
                  否 → 是否在 L3？是：拷贝到 L2 → L1
                       ↓
                       否 → 从主内存 RAM 加载 → 拷贝到 L3 → L2 → L1
```



### CPU 缓存和多线程编程的关系

**多核线程通信的延迟，本质是** **缓存同步问题**

- 每个核心都有自己的 L1/L2 缓存；
- 当**两个线程**运行在**不同核心**上时，彼此修改变量的可见性问题来自于**缓存不一致**；
- 这也是 Java 中 volatile、synchronized、内存屏障（fence）出现的根本原因；
- L3 缓存作为共享缓冲区，是**缓存一致性协议**（如 MESI）协调的基础。

# 计算机网络

## 1.为什么用比如迅雷下载器下载一个任务可以比用浏览器下载快

- **多线程分块下载**
  - 传统浏览器 **单线程顺序下载**，服务器按**FIFO（先进先出）**返回数据，速度受限。**单 TCP 连接受限于 TCP 拥塞控制**
  - 迅雷等下载器 **使用多个 TCP 连接，同时请求不同的文件块**。**多个 TCP 连接**可以提升**带宽利用率**。
- **P2P 传输**
  - 迅雷等 P2P 下载工具可以**从多个用户共享的资源中下载不同部分**
  - ​	**浏览器**：只能从**服务器 A 下载**，如果服务器带宽小，速度会受限
  - **迅雷**：可以从**多个用户（B、C、D）下载不同片段**，并合并
- **CDN（内容分发网络）加速**
  - 浏览器通常直接从源站下载，路径较长
  - 迅雷等下载器**自动选择离用户最近的 CDN 节点**，减少延迟



## 2.如何预防 DDoS 攻击？

**DDoS（分布式拒绝服务攻击，Distributed Denial of Service）** 是通过大量流量请求**耗尽服务器资源**，导致服务不可用。

- **限制 IP 访问频率**，检测单个 IP 发送的请求速率，**超过阈值则限流**。可以用nginx限流
- **泛洪攻击**也是ddos攻击的一种，利用 TCP 握手未完成占满服务器连接。可以用 **SYN cookies**，这种技术通过在 **SYN-ACK 响应**中编码连接信息，从而在不占用大量资源的情况下验证客户端
- **使用分布式架构**，攻击流量均衡到不同节点，防止单点崩溃。可以采用nginx负载均衡策略
- **阻止异常 IP（黑名单 / 地理封锁）**，可以用nginx屏蔽特定ip







# 设计原则

## **单一职责原则（SRP）**

> 一个类只负责一类功能，**不要让一个类承担太多职责**

- 用户类不应该既负责登录认证，又负责数据库存取。
- Controller 不要写业务逻辑；应该由 Service 承担。



## **开闭原则（OCP）**

> 对**扩展开放**，对**修改关闭**。不要修改已有代码，而是通过扩展实现新功能。

- 使用抽象接口 + 实现类，新增功能时继承接口而不是改原有逻辑。
- Spring 的 @Handler 方式或策略模式，新增 handler 不改主流程。



## **里氏替换原则（LSP）**

> 子类必须能够替换掉父类，程序行为不出错。

- 子类不要违背父类的预期，比如父类中有 add() 方法，子类不能重写为 throw Exception。
- ArrayList 可以替换 List，但不能用 Stack 替换 Queue。



## **接口隔离原则（ISP）**

> 一个接口不要包含不需要的冗余方法，应拆成小而精的接口。

- 不要搞一个超级接口 Animal { eat(), run(), swim(), fly() }；
- 而应拆成 Runnable, Swimmable, Flyable 等小接口，按需组合。



##  **依赖倒置原则（DIP）**

> 高层模块不依赖底层模块，依赖**抽象（接口）**；抽象不依赖具体，实现依赖抽象。

- Service 不要依赖具体的 Dao 实现类，应依赖 Dao 接口；
- 使用 Spring IOC 容器注入接口实现类。



# CAP

CAP理论描述了**分布式系统中三者不可兼得**

| **缩写**                    | **含义**                                         |
| --------------------------- | ------------------------------------------------ |
| **C - Consistency**         | 一致性，所有节点数据一致                         |
| **A - Availability**        | 可用性，每个请求都能及时返回（不保证是最新数据） |
| **P - Partition Tolerance** | 分区容错性，网络断开后系统仍能运行               |

**定理核心：在出现网络分区（P）时，只能在一致性（C）和可用性（A）之间做权衡，不能三者兼得。**



## **CAP 的经典场景理解**

| **场景**                     | **CAP组合** | **特点**                                 |
| ---------------------------- | ----------- | ---------------------------------------- |
| **传统关系型数据库主从同步** | CP          | 保证一致性，但可能牺牲可用（从库不可写） |
| **DNS / 购物车缓存系统**     | AP          | 保证可用和容错，允许数据暂时不一致       |
| **Zookeeper / Paxos 系统**   | CP          | 强一致性，牺牲部分可用性                 |
| **Cassandra / Couchbase**    | AP          | 牺牲强一致性，保证高可用和分区容忍       |



## **实际应用中的 CAP 权衡**

- **很多实际系统选的是 AP（高可用 + 分区容忍）**，然后通过**最终一致性**来补偿 C；
- **分布式缓存（如 Redis 集群）**常选 AP，因为读写性能优先；
- **金融系统（如银行转账）**常选 CP，牺牲一点可用，确保数据正确；
- **MQ（如 RocketMQ）**默认追求 AP，但消费者可实现幂等性补偿一致性。



# Docker



## **✅ 一、Docker 基础类问题**



### **1️⃣ 什么是 Docker？它解决了什么问题？**



**回答要点：**

- Docker 是一个开源的容器化平台。
- 通过容器打包**应用**及其**依赖**，实现“**一次构建，到处运行**”。
- 解决传统部署中**环境不一致、部署繁琐、资源浪费**的问题。



------





### **2️⃣ 容器和虚拟机的区别？**



| **对比项**   | **容器（Docker）**         | **虚拟机（VM）**            |
| ------------ | -------------------------- | --------------------------- |
| **启动速度** | 秒级                       | 分钟级                      |
| **资源隔离** | 基于**内核**（**进程级**） | 基于 Hypervisor（完整系统） |
| **占用资源** | **少**（共享宿主机内核）   | 多（独立系统）              |
| 适用场景     | 微服务、CI/CD              | 全栈隔离、安全强场景        |





------



### **3️⃣ Docker 的核心组件有哪些？**



**回答要点：**

- Docker **Engine**：Docker 引擎，包括守护进程和 CLI
- 镜像（**Image**）：应用**打包模板**（可理解为**类**）
- 容器（**Container**）：**镜像运行实例**（可理解为**对象**）
- **Dockerfile**：镜像**构建脚本**
- Registry：镜像仓库（如 Docker Hub）





------





## **✅ 二、镜像与容器操作类**

### **4️⃣ 常见的 Docker 命令有哪些？**



**关键命令：**

```
docker build -t myapp .         # 构建镜像
docker run -d -p 8080:80 myapp  # 后台运行容器
docker ps -a                    # 查看所有容器
docker exec -it <id> /bin/bash  # 进入容器
docker stop <id>                # 停止容器
docker rm <id>                  # 删除容器
docker rmi <image>              # 删除镜像
```



------





### **5️⃣ 镜像层是如何工作的？**



**回答要点：**

- Docker 镜像由多层只读层组成（基于 Union FS）。
- 每一层代表一次构建指令（如 RUN、COPY）。
- 容器启动时，会添加一层读写层（container layer）。



------



### **6️⃣ Dockerfile 常见指令有哪些？**



| **指令** | **作用**               |
| -------- | ---------------------- |
| FROM     | 指定基础镜像           |
| RUN      | 执行命令（在构建阶段） |
| COPY     | 拷贝本地文件到镜像中   |
| CMD      | 容器启动时执行的命令   |
| EXPOSE   | 声明服务端口           |
| ENV      | 设置环境变量           |
| WORKDIR  | 设置工作目录           |





------





## **✅ 三、Docker 网络与存储类**



### **7️⃣ Docker 支持哪几种网络模式？**



| **模式**   | **说明**                             |
| ---------- | ------------------------------------ |
| **bridge** | 默认模式，容器间通过**虚拟网桥**通信 |
| host       | 容器与宿主机共用网络（无隔离）       |
| none       | 完全隔离网络                         |
| container  | 多容器共享同一网络命名空间           |
| overlay    | 跨主机网络（Swarm、K8s）             |





------





### **8️⃣ Docker 如何实现数据持久化？**



**方式有三种：**

- **Volume**（推荐，**专用挂载目录**）
- Bind Mount（绑定宿主机目录）
- tmpfs（内存挂载，重启即丢）



```
docker run -v mydata:/app/data myapp
```





------





## **✅ 四、Docker Compose 与集群**



### **9️⃣ Docker Compose 是做什么的？**



**回答要点：**



- 用于**定义和管理多容器应用**。
- 通过 docker-compose.yml 文件定义服务、网络、卷等。
- 简化了多个容器的启动、停止、依赖管理。



常用命令：

```
docker-compose up -d
docker-compose down
```





------





### **🔟 Docker Swarm 和 Kubernetes 有什么区别？**



| **对比项** | **Swarm**           | **Kubernetes**         |
| ---------- | ------------------- | ---------------------- |
| 学习成本   | 低                  | 高                     |
| 功能丰富   | 少（仅限于 Docker） | 强大（跨容器平台）     |
| 社区支持   | 较少                | 非常广泛，已成事实标准 |





------



## **✅ 五、扩展类经典问答**



### **1️⃣ 如何优化 Docker 镜像构建？**



**优化建议：**

- 使用 .dockerignore 排除无关文件
- 合并 RUN 语句，减少镜像层
- 使用多阶段构建（multi-stage build）
- 使用轻量基础镜像（如 alpine）



------



### **2️⃣ 容器运行时出错，如何排查？**



**排查路径建议：**



1. docker ps -a 查看状态
2. docker logs <id> 看日志
3. docker inspect <id> 查看配置详情
4. docker exec -it 进入容器排查依赖/端口等





------



## **✅ 六、项目实战类（简述场景）**



### **3️⃣ 在你的项目中是如何使用 Docker 的？**



> “我们将后端服务、Redis、MySQL 全部容器化部署，并通过 docker-compose.yml 管理各模块。前后端打包镜像后发布到公司私有 Harbor 仓库，通过 GitLab CI/CD 自动拉取并部署上线。”



------



## **✅ 七、总结建议（面试时）**



- 熟练掌握 Dockerfile、容器/镜像操作
- 能说出你用过 Docker 的实际场景（部署、调试、测试等）
- 能回答 Docker 的基本原理（镜像层、容器机制）
- 对 Compose / 网络 / 持久化 / CI 集成有清晰认识

