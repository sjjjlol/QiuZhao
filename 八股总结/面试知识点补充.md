# MySql

## 1.数据库层面发生死锁怎么办？

事务 A、事务 B 交叉持有锁

```sql
-- 事务 A
BEGIN;
UPDATE orders SET amount = 500 WHERE id = 1; -- 锁住 `id = 1`
UPDATE orders SET amount = 300 WHERE id = 2; -- 等待 `id = 2`

-- 事务 B
BEGIN;
UPDATE orders SET amount = 400 WHERE id = 2; -- 锁住 `id = 2`
UPDATE orders SET amount = 600 WHERE id = 1; -- 等待 `id = 1`

```

解决方法：
保持固定的加锁顺序：事务 A 和 事务 B 都按 `先锁 T1 再锁 T2` 进行操作



## 2.Sharding-Sphere分库分表的数据源存在什么地方？

### 核心原理

- SQL 解析

  - ```sql
    SELECT * FROM user WHERE user_id = 123;
    ```

  - ```
    表名: user
    查询条件: user_id = 123
    ```

- 分库分表路由

  - ```sql
    databaseShardingAlgorithm: user_id % 2
    tableShardingAlgorithm: user_id % 4
    ```

  - ```
    user_id=123：
    
    数据库：user_db_1
    
    表：user_table_3
    ```

- SQL 改写

  - ```
    SELECT * FROM user_table_3 WHERE user_id = 123;
    ```

- SQL 执行

  - 并行执行 SQL，提高性能

- 结果合并

  - **如果 SQL 查询涉及多个分片，ShardingSphere 需要合并结果**, 举个例子

  - ```sql
    SELECT COUNT(*) FROM user;
    ```

  - ```sql
    COUNT(user_db_0.user_table_0) + COUNT(user_db_0.user_table_1) + COUNT(user_db_1.user_table_2) + COUNT(user_db_1.user_table_3)
    ```

### 数据源配置

```yaml
spring:
  shardingsphere:
    datasource:
      names: ds0, ds1  # 数据源名称
      ds0:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/user_db_0
        username: root
        password: 123456
      ds1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/user_db_1
        username: root
        password: 123456

```



### 分库分表场景下如何生成全局唯一主键？

> **分库分表之后，每张表只能看到“自己那一部分数据”，不能用自增主键。必须使用分布式主键生成方案。**

![image-20250403174521440](./面试知识点补充.assets/image-20250403174521440.png)



### 怎么保证雪花算法的唯一性？

雪花算法id

```
[ 1bit | 41bit时间戳 | 10bit机器+数据中心ID | 12bit序列号 ]
```

​	•	1 bit：最高位固定为 0（正数）

​	•	41 bit：当前**时间戳**（毫秒）— 可用约 69 年

​	•	10 bit：**机器 ID**（5 bit 机房ID + 5 bit 机器ID）— 最多支持 1024 台节点

​	•	12 bit：**每毫秒内的自增序列** — 支持每台机器每毫秒生成 4096 个 ID



**只要每台机器 ID 不冲突，时间有序，序列号在一个毫秒内不重复，就能全局唯一。**





## 3.索引中能不能有 NULL？NULL 与其他值比较会怎样？



![image-20250403174059063](./面试知识点补充.assets/image-20250403174059063.png)



> 索引中是可以包含 NULL 值的，普通索引和唯一索引都允许，只要主键不允许。

> 由于 SQL 中 NULL != NULL，所以多个 NULL 插入唯一索引不会冲突。

> 判断 NULL 不能用 = NULL，要用 IS NULL；否则可能导致查询失败、索引失效。

# JUC

## 1.用线程池去多线程地解析一个很大的文件，如何操作？如何选择阻塞队列？

**问题分析**：

1. **文件很大，不能一次性加载到内存**。
2. **需要使用线程池，并发解析文件**，提高处理效率。
3. 如何选择合适的阻塞队列？
   - 任务队列需要考虑**生产者-消费者模型**。
   - 任务不能堆积太多，否则会造成内存溢出。

**SynchronousQueue 带来的好处**

**`SynchronousQueue` 不存任务，必须立刻消费，防止任务堆积**。

**如果消费者消费速度慢，生产者会阻塞，防止内存占用过高**。

**适用于“实时消费，不能积压”的场景，如日志解析、在线流处理。**



1. 生产者线程
   - 逐行读取大文件，将行数据提交到 `SynchronousQueue`。
   - **如果消费者处理慢，生产者会阻塞，防止过多任务积压**。
2. 消费者线程（线程池）
   - 直接从 `SynchronousQueue` 获取任务，**消费完成才能继续生产**。
   - 确保消费者能及时处理任务，避免积压。

如何保证文件解析高效？

**使用 `BufferedReader` 逐行读取文件，避免一次性加载**。

**使用 `SynchronousQueue` 控制任务流，避免积压**。

**线程池 `maximumPoolSize` > `corePoolSize`，让消费者根据负载自动扩展**。

**消费者进行** **异步批量处理，提高吞吐量**（如 Kafka/数据库写入）。



## 2.如果线程池嵌套线程池，可能会有什么问题？

> 线程池嵌套线程池可能导致任务被**死锁**卡住或**线程资源耗尽**，最终引发“线程饥饿”或“任务阻塞”的问题。

```java
ExecutorService pool = Executors.newFixedThreadPool(1);

Runnable outerTask = () -> {
    System.out.println("外层任务启动：" + Thread.currentThread().getName());

    Future<String> future = pool.submit(() -> {
        System.out.println("内层任务执行：" + Thread.currentThread().getName());
        return "inner done";
    });

    try {
        String result = future.get(); // ❗同步等待，当前线程卡住了
        System.out.println("结果：" + result);
    } catch (Exception e) {
        e.printStackTrace();
    }
};

pool.submit(outerTask);
```



# Redis

## 1.脑裂问题

![image-20250327154046837](./面试知识点补充.assets/image-20250327154046837.png)

![image-20250327154250478](./面试知识点补充.assets/image-20250327154250478.png)

### 脑裂带来的危害

![image-20250327154336466](./面试知识点补充.assets/image-20250327154336466.png)

### 解决方案

![image-20250327154502119](./面试知识点补充.assets/image-20250327154502119.png)



## 2.redis分布式锁和redisson分布式锁的区别？

Redis 分布式锁：使用 `SET NX EX`

**存在的问题**

1️⃣ **锁过期问题**：业务未完成，锁已自动过期，被其他线程抢占。
 2️⃣ **非可重入问题**：同一线程再次获取锁会失败，导致死锁。
 3️⃣ **非公平锁**：多个线程竞争时，可能某个线程一直抢不到锁。
 4️⃣ **Redis 主从复制延迟问题**：如果锁写入主节点，但还未同步到从节点，主节点宕机，可能导致**多个线程获取到相同的锁**（即锁丢失）。



Redisson 实现分布式锁

### **Redisson 优势**

1️⃣ **可重入锁**（同一线程可多次获取，不会死锁）。hash表实现
 2️⃣ **自动续期**（默认 `30s` 过期，且会**自动续期**，不会因业务执行时间过长导致锁提前释放）。独立的看门狗线程实现



## 3.假如数据库更新，删除了几个数据，布隆过滤器怎么处理？

### 为什么普通布隆过滤器不能直接删除数据？

###### 布隆过滤器使用 **多个哈希函数** 将 **一个 key 映射到多个 bit 位**

- **不能删除的原因**：
  - **多个 key 可能共用相同 bit 位**（哈希冲突）。
  - **如果直接把 bit 置 `0`，可能影响其他 key**（误删）。
  - **布隆过滤器本质上是单向 `set` 操作，无法反向 `unset`**。

### 解决方案

#### 重建布隆过滤器

 **适用场景**

- **数据删除量较大，布隆过滤器误判率较高**。
- **数据库支持批量查询，允许重新构建 Bloom Filter**。

**周期性重新构建布隆过滤器**（如每天、每周）。

**重新遍历数据库，插入最新的数据集合**



#### 使用计数布隆过滤器

原理：

- 计数布隆过滤器（CBF）**用整数数组替代 bit 数组**：

- **数据新增**：多个哈希函数对应的位置 `+1`。
- **数据删除**：多个哈希函数对应的位置 `-1`（如果 `count = 0`，表示删除）。

缺点：

**占用内存更大**（比普通 Bloom Filter 多 4~8 倍）。

**仍然可能出现误判（如果 `counter` 不准确）**。

# RocketMQ

## 1.RocketMQ的事务？

### **为什么需要 RocketMQ 的事务消息？**

在优惠券秒杀中，我们通常：

1. Redis 成功扣减库存；
2. **异步发送 MQ 消息通知消费者写入数据库。**

> 这中间就有问题了：如果 Redis 扣减成功了，但 MQ 发送失败？或者 MQ 成功了但消费者写入数据库失败了？

**RocketMQ 的事务消息能做什么？**

RocketMQ 事务消息可以把 **本地事务执行 和 消息的发送状态 强一致绑定起来**，避免“扣库存成功但数据库写入失败”或“反之”这种状态。



### **RocketMQ 事务消息的原理机制**

RocketMQ 事务消息基于**两阶段提交协议（Two-Phase Commit, 2PC）**设计：

事务消息有三个状态：

| **状态**         | **含义**                            |
| ---------------- | ----------------------------------- |
| COMMIT_MESSAGE   | 提交事务，消费者可见                |
| ROLLBACK_MESSAGE | 回滚事务，消息丢弃                  |
| UNKNOW           | 不确定状态，RocketMQ 将回查本地事务 |



### **两阶段执行流程**

**👉 第一阶段：**

**发送 Half 消息（Prepare 消息）**

- 发送方调用 sendMessageInTransaction() 方法
- RocketMQ 会把这条消息存入 “事务消息专用队列”，但**消费者此时不可见**



**👉 第二阶段：**

**执行本地事务**

- 回调执行器 executeLocalTransaction() 被触发，你在这一步完成业务操作（如写数据库）



**👉 第三阶段：**

**根据本地事务结果执行 COMMIT 或 ROLLBACK**

- 如果事务执行成功，调用 transactionExecuter.commit() → 该消息对消费者可见
- 如果失败，则调用 rollback() → 消息被丢弃



 **如果消息生产者崩溃，RocketMQ 会如何处理？**

- RocketMQ 会定时发起**事务状态回查请求（Check）**，调用生产者本地的 checkLocalTransaction() 方法确认事务结果
- 开发者需实现这个接口，并返回事务状态



### **实际应用：下单扣库存 + 支付订单创建**

> **目标：既要扣 Redis 库存，又要写数据库领券记录，且要保证一致性。**

**背景需求**

```
用户点击「立即购买」，需要：
	•	A. 在本地系统中创建订单（写入数据库）
	•	B. 通知库存中心，扣减库存（通过消息）
```

**问题**

```
如果我们先写库，再发消息，可能出现写库成功但发消息失败；
如果先发消息，再写库，也存在写入失败但消息已发出去的问题。
```

**使用事务消息的目标**

```
只要订单创建成功，才能通知库存系统扣减库存；
如果订单创建失败，就不应该扣库存。
```

执行流程图

```
用户请求下单
     ↓
sendMessageInTransaction("扣库存消息")
     ↓
↓Prepare消息存入MQ（消费者不可见）
↓
回调本地 executeLocalTransaction() → 创建订单写库
     ↓
写库成功         写库失败
↓                    ↓
COMMIT        ROLLBACK
消息可见        消息丢弃
↓
库存系统消费者 → 扣减库存

如果生产者崩溃，RocketMQ 会触发 checkLocalTransaction() 回查
```

生产者代码

```java
// 执行本地事务
public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
    Order order = parseOrder(msg);
    boolean success = orderService.createOrder(order);
    return success ? COMMIT_MESSAGE : ROLLBACK_MESSAGE;
}

// 回查事务状态
public LocalTransactionState checkLocalTransaction(Message msg) {
    String orderId = msg.getKeys();
    if (orderService.isOrderExist(orderId)) {
        return COMMIT_MESSAGE;
    } else {
        return ROLLBACK_MESSAGE;
    }
}
```

总结

> **RocketMQ 事务消息是通过“发送半消息 + 回调本地事务 + 状态回查”机制，实现分布式操作与消息发送之间的强一致性保障。**

# JVM

## 1.JVM 最多能占系统多大内存？

理论上，对于64位系统，单个进程内存的最大寻址空间为2的64次方，非常大了，基本可以当作没有限制，所以-Xmx的最大值可以认为是无限大。

实际上，JVM 不能超过系统的**总物理内存（RAM）**，在 Linux 系统上，建议 JVM 使用物理内存的 80% 以下；

若超出了，如果启用了交换空间（swap 或 pagefile），JVM 可能会使用**物理内存 + swap** 作为运行时的可用内存

# 操作系统

## 1.系统最大内存指的是什么？

64位操作系统，理论寻址空间 **16EB（2^64）**，但受限于 RAM 和 Swap。

**系统最大内存** = 物理内存（RAM） + **虚拟内存**（Swap/Pagefile）（虚拟内存通常建议 Swap 大小 ≈ 物理内存）



## 2.虚存理论最大值是什么？

虚拟内存最大值理论上是**寻址空间**的大小。

64位操作系统，理论寻址空间 **16EB（2^64）**



## 3.协程了解吗？介绍一下，协程里面用 ThreadLocal 会有问题吗？

**协程（Coroutine）** 是一种比线程（Thread）更**轻量级**的并发执行单元。协程 由**用户态**调度，切换成本低（只需保存和恢复寄存器、栈等）

**协程中使用 `ThreadLocal` 可能会导致意外行为**，因为 `ThreadLocal` 绑定的是 **物理线程**，而协程在**多个物理线程上调度**时，`ThreadLocal` 可能无法正确传递。

比如，一个协程 **起初运行在 A 线程**，然后因挂起切换到 **B 线程** 继续执行，原来存储在 `ThreadLocal` 中的变量无法自动传递到新线程

解决方案：使用**TransmittableThreadLocal**，适用于 Java 线程池/虚拟线程



## 4.多线程和异步IO的对比

### 多线程方案

![img](https://ask.qcloudimg.com/http-save/yehe-1161110/c1541843uc.jpeg)

**每个请求由一个独立线程处理**，使用线程池控制线程数量

多线程的适用范围则是那种需要**长时间CPU**运算的场合，例如耗时较长的图形处理和算法执行。

但是往往由于使用线程编程的简单和符合习惯，所以很多朋友往往会使用多线程来执行耗时较长的I/O操作。



```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class MultiThreadExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(5); // 线程池大小 5

        for (int i = 0; i < 10; i++) {
            int taskId = i;
            executor.execute(() -> {
                System.out.println("线程 " + Thread.currentThread().getName() + " 处理任务 " + taskId);
                try { Thread.sleep(1000); } catch (InterruptedException ignored) { }
            });
        }

        executor.shutdown(); // 关闭线程池
    }
}

```



### 异步IO方案

![img](https://ask.qcloudimg.com/http-save/yehe-1161110/7g4kckddvp.jpeg)

**使用 `CompletableFuture` 或 `Netty` 进行异步非阻塞 IO**。

当需要执行**I/O操作**时，使用**异步**操作比使用**多线程+同步I/O**操作更合适。I/O操作不仅包括了直接的文件、网络的读写，还包括数据库操作、Web Service、HttpRequest以及.Net Remoting等跨进程的调用。

```java
import java.util.concurrent.CompletableFuture;

public class AsyncIOExample {
    public static void main(String[] args) {
        for (int i = 0; i < 10; i++) {
            int taskId = i;
            CompletableFuture.runAsync(() -> {
                System.out.println("线程 " + Thread.currentThread().getName() + " 异步处理任务 " + taskId);
                try { Thread.sleep(1000); } catch (InterruptedException ignored) { }
            });
        }

        try { Thread.sleep(2000); } catch (InterruptedException ignored) { } // 等待任务完成
    }
}

```



### 多线程和异步的区别

多线程是关于功能的并发执行。而异步编程是关于函数之间的非阻塞执行，我们可以将异步应用于单线程或多线程当中。

因此，**多线程只是异步编程的一种实现形式**。

比如，你和你的朋友决定一起做一顿午餐。“异步”就是你对朋友说：“你去商店买意大利面，回来的时候告诉我一声，然后一起做午餐。在你买意大利面的同时，我去准备番茄酱和饮料。”

而“线程”是：“你烧水，我加热番茄酱。当水烧开了，告诉我，我把意大利放进去。当番茄酱热了，你可以把奶酪添加进去。当两者都完成了，就可以坐下来一起吃晚餐。”在线程的示例中，我们可以看到“When，Do”的事件顺序，而这些顺序代表着每个人（线程）的指令集集合的顺序。

上述示例可以看出，多线程是与具体的执行者相关的，而异步是与任务相关的。

多线程是程序设计的逻辑层概念，它是进程中并发运行的一段代码，可以实现线程间的切换执行。

异步和同步是相对的，异步就是彼此独立，在等待某事件的过程中继续做自己的事，不需要等待这一事件完成后再工作。

多线程就是实现异步的一个方式。异步是让调用方法的主线程不需要同步等待另一线程的完成，从而可以让主线程干其它的事情。

所以本质上，异步和多线程并不是一个同等关系，**异步是最终目的，多线程只是实现异步的一种手段**。



### 如何选择

面对多线程和异步，我们该如何选择呢？其实，通常情况下选择的依据是主要取决于性能。

那么，同步/异步与单线程/多线程之间的所有组合，哪种模型表现更好？

简而言之，对于具有大量I/O操作和不同计算的大规模应用程序，使用异步多线程有利于充分利用计算资源，并且能够照顾到非阻塞函数。这也是所有操作系统所采用的线程模型。

编写异步操作的复杂程度较高，程序主要使用回调方式进行处理，与正常的思维方式有些出入，而且难以调试。而多线程的使用（滥用）会给系统带来上下文切换的额外负担，并且线程间的共享变量可能造成死锁。

因此在实现这两种模式时，往往需要处理资源竞争、死锁、共享资源和回调事件等问题。



## 5. 什么是线程饥饿

> **线程饥饿（Thread Starvation）是指某些线程长时间无法获得 CPU 或其他资源，一直处于就绪态，导致迟迟不能执行或完成任务。**

> 常见原因包括高优先级线程长期占用 CPU、调度器不公平、资源独占等



## 6.静态库和动态库

> 静态库是在**编译时**被打包进可执行文件中的代码库，最终生成的程序文件中包含了库的全部代码；.lib（Windows）
>
> 动态库是在**运行时**才被加载进内存的**共享代码库**。.dll（Windows）

> 静态库体积大、更新麻烦但运行独立；动态库体积小、易于维护，多个程序还能共享同一份内存，是现代操作系统下更常见的库加载方式。



## 二维数组是行优先还是列优先遍历效率高

**二维数组是行优先遍历效率更高**，这是因为**底层内存布局是按“行优先”方式存储的**

为什么？

- **内存布局**
  - **每一行在内存中是连续存储的**，而不同的行彼此之间不是连续的
- **CPU 缓存友好性**
  - **行优先：** 每次访问都在同一行，访问的是连续内存，**CPU 会将整个缓存行（cache line）加载进来，命中率高**
  - **列优先：** 每次跨行，访问的是不同数组对象，**CPU 每次都要加载新的地址，缓存命中率低，性能差**。

# 计算机网络

## 1.为什么用比如迅雷下载器下载一个任务可以比用浏览器下载快

- **多线程分块下载**
  - 传统浏览器 **单线程顺序下载**，服务器按**FIFO（先进先出）**返回数据，速度受限。**单 TCP 连接受限于 TCP 拥塞控制**
  - 迅雷等下载器 **使用多个 TCP 连接，同时请求不同的文件块**。**多个 TCP 连接**可以提升**带宽利用率**。
- **P2P 传输**
  - 迅雷等 P2P 下载工具可以**从多个用户共享的资源中下载不同部分**
  - ​	**浏览器**：只能从**服务器 A 下载**，如果服务器带宽小，速度会受限
  - **迅雷**：可以从**多个用户（B、C、D）下载不同片段**，并合并
- **CDN（内容分发网络）加速**
  - 浏览器通常直接从源站下载，路径较长
  - 迅雷等下载器**自动选择离用户最近的 CDN 节点**，减少延迟



## 2.如何预防 DDoS 攻击？

**DDoS（分布式拒绝服务攻击，Distributed Denial of Service）** 是通过大量流量请求**耗尽服务器资源**，导致服务不可用。

- **限制 IP 访问频率**，检测单个 IP 发送的请求速率，**超过阈值则限流**。可以用nginx限流
- **泛洪攻击**也是ddos攻击的一种，利用 TCP 握手未完成占满服务器连接。可以用 **SYN cookies**，这种技术通过在 **SYN-ACK 响应**中编码连接信息，从而在不占用大量资源的情况下验证客户端
- **使用分布式架构**，攻击流量均衡到不同节点，防止单点崩溃。可以采用nginx负载均衡策略
- **阻止异常 IP（黑名单 / 地理封锁）**，可以用nginx屏蔽特定ip







# 设计原则

## **单一职责原则（SRP）**

> 一个类只负责一类功能，**不要让一个类承担太多职责**

- 用户类不应该既负责登录认证，又负责数据库存取。
- Controller 不要写业务逻辑；应该由 Service 承担。



## **开闭原则（OCP）**

> 对**扩展开放**，对**修改关闭**。不要修改已有代码，而是通过扩展实现新功能。

- 使用抽象接口 + 实现类，新增功能时继承接口而不是改原有逻辑。
- Spring 的 @Handler 方式或策略模式，新增 handler 不改主流程。



## **里氏替换原则（LSP）**

> 子类必须能够替换掉父类，程序行为不出错。

- 子类不要违背父类的预期，比如父类中有 add() 方法，子类不能重写为 throw Exception。
- ArrayList 可以替换 List，但不能用 Stack 替换 Queue。



## **接口隔离原则（ISP）**

> 一个接口不要包含不需要的冗余方法，应拆成小而精的接口。

- 不要搞一个超级接口 Animal { eat(), run(), swim(), fly() }；
- 而应拆成 Runnable, Swimmable, Flyable 等小接口，按需组合。



##  **依赖倒置原则（DIP）**

> 高层模块不依赖底层模块，依赖**抽象（接口）**；抽象不依赖具体，实现依赖抽象。

- Service 不要依赖具体的 Dao 实现类，应依赖 Dao 接口；
- 使用 Spring IOC 容器注入接口实现类。



# CAP

CAP理论描述了**分布式系统中三者不可兼得**

| **缩写**                    | **含义**                                         |
| --------------------------- | ------------------------------------------------ |
| **C - Consistency**         | 一致性，所有节点数据一致                         |
| **A - Availability**        | 可用性，每个请求都能及时返回（不保证是最新数据） |
| **P - Partition Tolerance** | 分区容错性，网络断开后系统仍能运行               |

**定理核心：在出现网络分区（P）时，只能在一致性（C）和可用性（A）之间做权衡，不能三者兼得。**



## **CAP 的经典场景理解**

| **场景**                     | **CAP组合** | **特点**                                 |
| ---------------------------- | ----------- | ---------------------------------------- |
| **传统关系型数据库主从同步** | CP          | 保证一致性，但可能牺牲可用（从库不可写） |
| **DNS / 购物车缓存系统**     | AP          | 保证可用和容错，允许数据暂时不一致       |
| **Zookeeper / Paxos 系统**   | CP          | 强一致性，牺牲部分可用性                 |
| **Cassandra / Couchbase**    | AP          | 牺牲强一致性，保证高可用和分区容忍       |



## **实际应用中的 CAP 权衡**

- **很多实际系统选的是 AP（高可用 + 分区容忍）**，然后通过**最终一致性**来补偿 C；
- **分布式缓存（如 Redis 集群）**常选 AP，因为读写性能优先；
- **金融系统（如银行转账）**常选 CP，牺牲一点可用，确保数据正确；
- **MQ（如 RocketMQ）**默认追求 AP，但消费者可实现幂等性补偿一致性。

