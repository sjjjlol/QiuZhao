# 自我介绍

面试官好，我是一名新加坡南洋理工信号处理专业在读的研究生，本科毕业于华东师范大学通信工程专业。在校期间，我学习了java后端开发相关技术栈，包括java基础，jvm，java并发编程，开发框架如ssm，SpringBoot，关系型数据库mysql以及中间件redis和rocketmq。本科期间，我多次获得奖学金，专业课成绩在年级前百分之10，参加蓝桥杯、全国大学生数学竞赛等竞赛并获奖。



# 项目介绍

我最近做的一个项目是这个仿美团优惠券系统项目，这个项目模拟了美团的优惠券管理和发放机制，系统架构可以分为后管模块（实现了商家平台创建优惠券模板，创建优惠券分发任务等业务）、分发模块（具体实现了解析excel文件，向目标用户发放优惠券。），引擎层（采用缓存等手段，实现高并发场景下优惠券的查询、秒杀、预约通知等功能），结算层（实现用户使用优惠券购物结算的业务）。项目中我使用了一些设计模式对代码进行重构优化，比如用责任链模式实现参数校验，模板方法模式实现RocketMQ发送消息的功能。用redis和Spring AOP自定义了幂等注解。还有用布隆过滤器、双重判定锁等解决了缓存穿透、缓存击穿问题等。还用批处理优化了优惠券分发逻辑，解析分发5000条记录的时间从1分钟提升到了1s。



这个是电商平台中的某个系统，一般来说是配合营销系统来完成业务闭环。



## 你为什么选择 RocketMQ 作为消息队列，而不是 Kafka 或 RabbitMQ？

RocketMQ5.X支持任意时间的延时消息，通过设置最高能延迟1年，阿里开源的中间件，社区环境好，网上能找到很多相关博客进行学习。kafka我不太了解，

# 1.  责任链设计模式重构方法



吟唱：

## **✅ 责任链模式在参数校验中的应用**

### **📌 背景与动因**

在项目中，**优惠券模板创建**和**优惠券推送任务**涉及复杂的风控逻辑与参数校验：

- 参数非空、格式合法性校验（如 JSON 格式）
- 参数依赖关系判断（如定时发送需设置延迟时间）
- 外部数据一致性校验（商品、券模板是否存在）
- 自定义风控策略（如恶意金额判断）

这些规则原本集中在 Service 层中，造成**职责不清、可维护性差、扩展困难**。因此我引入了**责任链模式**进行重构。

------



### **🔧 技术实现**

#### **1. 定义责任链接口**

```
public interface ChainHandler extends Ordered {
    void handle(RequestContext context);
    String mark(); // 标识责任链类型，例如"coupon_create"
}
```

#### **2. 编写多个 Handler 实现类**

- 每个 Handler 专注处理一个校验点
- 实现 Ordered 接口，支持优先级排序
- 如：
  - NotNullValidator
  - ValidDateRangeValidator
  - JsonFormatValidator
  - ProductExistenceValidator

#### **3. 构建责任链容器**

- 使用 Map<String, List<ChainHandler>> 管理各业务类型对应的责任链
- 启动时通过 CommandLineRunner 自动从 Spring 容器中加载所有 Handler，并按 order 排序

```
@Override
public void run(String... args) {
    Map<String, ChainHandler> beans = applicationContext.getBeansOfType(ChainHandler.class);
    for (ChainHandler handler : beans.values()) {
        chainMap
          .computeIfAbsent(handler.mark(), k -> new ArrayList<>())
          .add(handler);
    }
    chainMap.values().forEach(list -> list.sort(Comparator.comparing(Ordered::getOrder)));
}
```

#### **4. 执行责任链**

- 调用方根据业务场景获取对应责任链，按顺序执行
- Handler 可抛出异常终止链路，实现中断控制

------



### **✅ 应用举例**

#### **优惠券模板创建责任链（mark = “template_create”）：**

1. 基础字段非空校验
2. 优惠券类型合法性校验
3. 有效期合法性校验
4. 商品是否存在校验

#### **优惠券推送任务责任链（mark = “task_push”）：**

1. 参数非空校验
2. Excel 文件地址格式校验
3. 延迟发送参数是否填写

------



### **🚀 引入责任链模式的优势**

- **职责清晰**：每个校验类单一职责，逻辑清晰
- **易于扩展**：新增校验规则仅需新增一个 Handler，无需改动原有代码
- **可配置性强**：基于 mark 动态组装责任链，适配多种业务
- **符合开闭原则**：扩展开放、修改关闭



------



### 具体描述

**优惠券模板创建**时的参数验证，包括**参数非空**，**参数关系正确**（优惠券来源 0：店铺券 1：平台券，优惠类型 0：立减券 1：满减券 2：折扣券，有效期开始时间的合法性），**参数依赖关系**（调用商品中台验证商品是否存在）

**优惠券推送任务**时的参数验证，**参数非空**，**excel文件地址是否合法**，**参数依赖关系**（定时发送，延迟时间是否不为空）。

定义**责任链接口**，里面有**handle**方法（执行验证逻辑），**mark**方法（标志是同一个业务的验证责任链）。

**实现类**，实现接口，完成实际的handle方法验证，同时实现order接口，设置优先级

**责任链存储容器**，里面有一个**map**，key是**mark**，value是存储具体责任链的**容器**； **handle**方法，获取特定mark的**一组责任链**进行验证。

实现CommandLineRunner，ApplicationContextAware，程序启动后从Spring容器里面加载责任链，并按照优先级排序。

```java
@Override
    public void run(String... args) throws Exception {
        // 从 Spring IOC 容器中获取指定接口 Spring Bean 集合
        Map<String, MerchantAdminAbstractChainHandler> chainFilterMap = applicationContext.getBeansOfType(MerchantAdminAbstractChainHandler.class);
        chainFilterMap.forEach((beanName, bean) -> {
            // 判断 Mark 是否已经存在抽象责任链容器中，如果已经存在直接向集合新增；如果不存在，创建 Mark 和对应的集合
            List<MerchantAdminAbstractChainHandler> abstractChainHandlers = abstractChainHandlerContainer.getOrDefault(bean.mark(), new ArrayList<>());
            abstractChainHandlers.add(bean);
            abstractChainHandlerContainer.put(bean.mark(), abstractChainHandlers);
        });
        abstractChainHandlerContainer.forEach((mark, unsortedChainHandlers) -> {
            // 对每个 Mark 对应的责任链实现类集合进行排序，优先级小的在前
            unsortedChainHandlers.sort(Comparator.comparing(Ordered::getOrder));
        });
    }
```



## 创建优惠券模板其他逻辑

用Redis的**Hash结构**做缓存预热，因为优惠券模板存在库存，而我们后续会通过缓存扣减，如果使用字符串没办法做原子自减，而使用 Redis Hash 结构是可以针对某个字段进行自减的。

缓存的过期时间就用  expireAt（valid_end_time）



# 2.模板方法设计模式重构方法

定义一个抽象类

实现一个消息**发送通用方法**

- 将消息发送的逻辑（从传入的消息发送事件中取出**延迟时间**，根据**延迟时间**是否为空，判定是延迟消息还是立即消息）
- 结果**日志**（log.info("[生产者] {} - 发送结果：{}，消息ID：{}，消息Keys：{}）的打印进行了抽象。

定义抽象方法，实现对消息的包装。每个发送类去继承这个抽象类，重写**消息包装**方法，传进来的是只有关键字段的事件

- 包装方法实现发送实体的扩充，添加如name，topic，key。

举个例子

```
发送延时消息事件，优惠券活动到期修改优惠券模板状态
```

传入的参数，只有关键信息shopNumber，couponTemplateId，delayTime

```java
CouponTemplateDelayEvent templateDelayEvent = CouponTemplateDelayEvent.builder()
                .shopNumber(UserContext.getShopNumber())
                .couponTemplateId(couponTemplateDO.getId())
                .delayTime(couponTemplateDO.getValidEndTime().getTime())
                .build();
```

包装,加入eventName，keys（couponTemplateId提取），topic（前缀），delayTime

```java
 @Override
    protected BaseSendExtendDTO buildBaseSendExtendParam(CouponTemplateDelayEvent messageSendEvent) {
        return BaseSendExtendDTO.builder()
                .eventName("优惠券模板关闭定时执行")
                .keys(String.valueOf(messageSendEvent.getCouponTemplateId()))
                .topic(environment.resolvePlaceholders(MerchantAdminRocketMQConstant.TEMPLATE_TEMPLATE_DELAY_TOPIC_KEY))
                .delayTime(messageSendEvent.getDelayTime())
                .build();
    }
```



# 3. 幂等注解怎么实现的

我使用了noMQConsume注解，通过redis存幂等标识判断消息的消费情况，防止重复消费。

面试官如果问可能有什么问题，答：不是完全解决幂等，只是从消息队列的层面防重复。

**不能保证事务的幂等。例如中途消息挂了导致重试，已经操作的内容会进行重复操作。**



**具体**：

自定义注解，用SpringAOP加强。通过lua脚本 SET KEY VAL NX GET PX。当redis中存在这个key的时候，不进行set，而是直接返回redis中的值。0就是消费中，这是抛出异常（消费中），让RocketMQ重试（**为了解决并发消费问题**），1就是消费完成，直接返回；当消息在redis中不存在的时候，返回的是null（说明第一次消费），先将val设置为0（消费中），执行业务逻辑，执行成功后，将val设置为1（消费完成），并设置过期时间，若执行业务失败抛出了一场，则删除key，并抛出异常重试。

key由 **业务前缀keyPrefix** + **消息的key**组成

```java
@NoMQDuplicateConsume(
            keyPrefix = "coupon_task_execute:idempotent:",
            key = "#messageWrapper.message.couponTaskId",
            keyTimeout = 120
    )
```



### **为什么返回 0（消费中）时，要抛出异常让 RocketMQ 重试？**

#### **主要目的：**

#### **避免并发消费同一条消息导致重复发券**

比如 RocketMQ 在集群消费模型下，同一条消息可能被多个消费者线程同时拉取（可能是同组内并发、也可能是 broker 重投）：

- 如果我们**不抛异常，而是直接 return，不做处理**，就会导致该线程“悄悄吃掉了这个消息”，但实际上业务并未执行！
- 而我们选择**抛出异常，告诉 RocketMQ 消费失败**，RocketMQ 会在一段时间后自动重试（默认 1 秒以上）

| **处理方式**        | **后果说明**                                                 |
| ------------------- | ------------------------------------------------------------ |
| ✅ 抛异常让 MQ 重试  | 确保之后只有一个线程执行了发券                               |
| ❌ 什么都不做 return | 该线程“吃掉了”这次消息消费的机会，但没执行逻辑，等于消息丢失！ |

在并发场景下，我们使用消息状态来实现并发控制，以使第二条消息被不断延迟消费（即重试）。但如果在此期间第一条消息也因某些异常原因（例如机器重启或外部异常）未成功消费，该怎么办呢？因为每次查询时都会显示消费中的状态，所以延迟消费会一直进行下去，直到最终被视为消费失败并被投递到死信 Topic 中（RocketMQ 默认最多可以重复消费 16 次）。

这就像：

- A 正在给用户发券，还没发完
- B 同时想发，但发现 A 已经在处理了
- B **不能自己决定不发也不报错**，而应该说：“我这次没法发，让 MQ 晚点再找我”



这样设计的好处

- 不会出现**多线程同时执行发券逻辑**
- 也不会出现**消费线程提前退出，导致消息丢失**
- 保证了**串行幂等消费**：只有第一个消费中的线程执行，其它等待重试



# ☆4.优惠券分发业务

## 流程图

(1)->（上一章的内容）后管服务创建分发任务表插入到数据库 -> 统计excel行数 -> 将行数插入优惠券分发任务表 ->发送定时消息或延时消息执行给分发引擎服务执行分发任务。

 (2) -> 校验消费者拿到消息并进行校验 -> 使用easyexal读取 -> Easyexcel监听类 记录执行点位 、执行缓存扣减，记录批量数据到缓存 -> 批量达到5000，发送消息给分发消费者 -> 分发消费者拿到消息(顺序执行) ->  批量保存到数据库 ->要是库存不足，批量记录到发放失败表 ->  更新分发任务表的完成时间



### **后台任务创建阶段**

```
[商家后台发起“分发任务”操作]
        ↓
[构建 CouponTaskDO 分发任务记录（状态=INIT）]
        ↓
[发送 MQ 消息：CouponTaskExecuteEvent（含 Excel 路径、任务信息等）]
        ↓
【分发模块启动，CouponTaskExecuteConsumer 消费消息】
```



### **消费端解析 Excel 文件（ReadExcelDistributionListener）**

```
[解析 Excel 文件的每一行记录]
        ↓
【步骤 1】构造 Redis 进度 key（templateTaskExecuteProgressKey）：
          - 查询当前 rowCount 是否 ≤ Redis 中记录的进度（容灾恢复）
          - 若是，说明宕机恢复中 ➝ 跳过当前行
        ↓
【步骤 2】构造 Lua 脚本参数：
          KEYS:
            - couponTemplateKey（库存字段 Hash）
            - batchUserSetKey（Set 存放未批量落库的用户）
          ARGV:
            - JSON(userId + rowNum)
        ↓
【步骤 3】执行 Lua（扣减库存 + 添加用户记录到 Redis Set）：
          - 若库存不足 ➝
            a) 写入 t_coupon_task_fail（标记失败行数 + 原因）
            b) 同步 rowCount 至 Redis，跳过
          - 若库存扣减成功：
            a) Redis Set add(userId+rowNum)
            b) 继续执行
        ↓
【步骤 4】判断当前 Redis Set 中用户数量是否达到 5000：
          ├─ 若 < 5000 且未配置 notifyType ➝ 只同步 rowCount
          └─ 若 ≥ 5000 或配置了 notifyType ➝ 构造 CouponTemplateDistributionEvent 发送 MQ
        ↓
[继续解析下一行]
```



### **用户券最终落库（CouponExecuteDistributionConsumer）**

```
[开始：消费 CouponTemplateDistributionEvent]
        |
        v
【1】调用：decrementCouponTemplateStock(event, batchSize)
        |
        ├─ MySQL UPDATE coupon_template SET stock = stock - ? WHERE id = ?
        |       → 若更新成功：返回 batchSize
        |       → 若失败：再次查当前库存，回退为真实剩余库存并返回
        ↓
【2】从 Redis Set 中 POP 出 couponTemplateStock 个用户发券记录（JSON）
      - key: batchUserSetKey = "template_task:batch_user:{taskId}"
      - value: {"userId":xxx,"rowNum":xxx}
        ↓
【3】构建 userCouponDOList（用户优惠券记录）
        |
        ├─ 设置：id（雪花ID）、userId、templateId、rowNum、有效期、状态
        └─ 每个对象是准备插入 t_user_coupon 的一条记录
        ↓
【4】执行批量 insert（MyBatis-Plus insert）
        |
        ├─ 插入成功 → 下一步
        |
        └─ 插入失败（可能因为重复领取等）：
              ↓
          [4.1] fallback：遍历 userCouponDOList，逐条 insert
              ↓
          [4.2] insert 时如果发现“已领取”：
              → 写入 t_coupon_task_fail 表（记录 rowNum + 原因）
              → 收集失败数据，从原 userCouponDOList 中移除
        ↓
【5】构造用户领券记录缓存数据（写入 Redis ZSet）：
        |
        ├─ 构建 couponId = templateId_couponId
        ├─ 构建 Redis key: user_coupon_list:{userId}
        └─ 执行 Lua 脚本（BATCH_SAVE_USER_COUPON_LUA_PATH）：
              → ZADD user_coupon_list:{userId} couponId score=receiveTime
        ↓
[结束：成功保存用户领取记录 + 写入缓存 + 失败用户记录已写入 fail 表]
```



## 问题

### 这个批处理和记录点位怎么实现的？

- 后管模块中，平台商家会创建优惠券分发任务，发送mq消息。

- 分发模块，**CouponTaskExecuteConsumer**进行 Excel 模板解析（ReadExcelDistributionListener），在消费者读取 Excel 执行记录时，如果发生宕机，消息队列在重试时需要重新执行整个任务，这显然会造成时间和资源的浪费。

- 为了优化这一点，我们在每次成功分发记录后，会将**进度行号**保存到缓存中，若宕机，下次执行的时候判断当前行号若小于等于**进度行号**，则直接跳过，直到达到上次的执行进度。

- lua脚本进行**库存扣减**以及记录**领券记录**，存到**set**中，key是batchUserSetKey是前缀+couponTaskId，value是ListUtil.of(couponTemplateKey, batchUserSetKey), JSON.toJSONString(userRowNumMap))
  - 若由于库存不足而分发失败，则写入到分发失败的数据库中。如果扣减失败，则将失败记录插入t_coupon_task_fail，记录失败原因：库存扣减失败。 并同步进度rowCount++到redis

- 如果不满足批量发送条件，数据应该暂存在 Redis 的 Set 缓存中，待满足批量条件时再从 Redis Set 中提取并执行批量保存。发送消息给CouponExecuteDistributionConsumer，将优惠券分发到用户账户

  - ```java
    CouponTemplateDistributionEvent couponTemplateDistributionEvent = CouponTemplateDistributionEvent.builder()
                    .userId(data.getUserId())
                    .mail(data.getMail())
                    .phone(data.getPhone())
                    .couponTaskId(couponTaskId)
                    .notifyType(couponTaskDO.getNotifyType())
                    .shopNumber(couponTaskDO.getShopNumber())
                    .couponTemplateId(couponTemplateDO.getId())
                    .couponTaskBatchId(couponTaskDO.getBatchId())
                    .couponTemplateConsumeRule(couponTemplateDO.getConsumeRule())
                    .batchUserSetSize(batchUserSetSize)
                    .distributionEndFlag(Boolean.FALSE)
                    .build();
            couponExecuteDistributionProducer.sendMessage(couponTemplateDistributionEvent);
    ```

- CouponExecuteDistributionConsumer，进行批量插入逻辑，这里用了**事务**。
- 为什么批量插入比单条插入快？

相同的 5000 条记录，v1 版本需要执行 1 分钟左右，v2 也就是当前版本仅需要 1 秒

每次都单条方式操作 Redis 和 MySQL，网络成本消耗巨大

**存在的问题**

如果 `batchSaveUserCouponList` 执行时数据库宕机，那么就会面临事务回滚问题，意味着我们需要将从 Redis 中获取的领券用户记录再保存到 Redis。





### easyExcel对比poi优势在哪？

#### **1. EasyExcel 相比 POI 的优势**

✅ **内存占用低**：

- POI 解析 Excel 需要 **把整个文件加载到内存**，容易OOM（尤其是大文件）。
- **EasyExcel 采用流式解析**，**基于 SAX 方式** 逐行读取，内存占用极低。

✅ **性能更高**：

- POI 处理 百万数据时，可能需要3G，甚至OOM。
- EasyExcel **仅占用200 MB**，速度更快，适用于大数据量 Excel 读写。



### 为什么批插入比单条插入快？

1.从 SIMPLE 执行模式变为 BATCH 执行模式，会**缓存预编译语句**，**相同 SQL 模板仅解析一次** ，**后续仅替换参数值**，避免重复解析 SQL

2.将多条 SQL **合并为一次数据库交互**，默认是 1000 提交一次，可以通过传入的参数修改，降低网络延迟。

3.采用手动事务模式（autoCommit=false） ，将所有操作纳入单个事务 ，**仅需 1 次提交** ，大幅减少事务管理的资源消耗（如**减少日志刷盘次数**）。



批处理主要体现在**redolog**刷盘的层面，**commit fsync，默认是commit一次同步刷一次**，还有其他两种策略一般不会使用的。

刷盘1000次就是1000次磁盘IO，**合成一次只有一次磁盘IO**。



### 分发接口能否同步知道是否分发成功？

 回答，目前不能？（当前异步处理，优惠券解析完成后，直接发送任务到消息队列，处理器直接返回成功，现在好像不管是否真的成功都在返回成功？） 

**追问**：现在让你考虑，你要如何设计，能够返回给前端是否分发成功？

可以在咱们完成后，对接个站内信或者邮件形式告知





# 5.缓存穿透和缓存击穿的解决方案

查询优惠券是个高并发的操作，采用**布隆过滤器**+**缓存空值**解决缓存穿透问题，使用**双重判定锁**重建缓存解决了缓存击穿问题。
先判断布隆过滤器里有没有这个key，如果没有就直接返回，如果有（可能是误判），在看看有没有空值，有的话也返回，然后用双重判定锁（先尝试获取锁，进去以后再次判定是否在缓存中有，【为了让只有第一个拿到锁的线程去完成缓存重建】，然后查询数据库完成缓存重建，**如果发现数据库中没有，则加入空值**）

这里布隆过滤器我设置了（1000，0.001）,只占用 2kb内存

如果设置（1亿， 0.001）实际容量大概在 170M， 且布隆过滤器有上限40亿

解决方案：设置多个布隆过滤器，使得这些分片的布隆过滤器总容量能达到 300 亿。然后根据模板 ID 进行分片，确定要操作的布隆过滤器，从而在该分片上进行操作



上线的项目，如何清理布隆过滤器：

- 创建新布隆过滤器

- 先让一部分流量使用 `bloom_filter_v2`，观察数据正确性。确保新布隆过滤器加载完成后，替换所有流量。

- 删除旧 的布隆过滤器





# 6.秒杀逻辑

## 业务流程

- 先验证要抢的券是否在缓存中，若不在的话会重建缓存，然后验证是否在有效时间内，再验证用户是否可以参与秒杀。

- 开始秒杀逻辑，用lua脚本查询库存是否大于0，以及用户是否达到领取上限，然后增加用户领券次数，最后执行库存预扣减。
  - 通过lua脚本在redis中的原子性 + redis本身的单线程，防止了超卖问题

- 然后发RocketMQ同步消息，去进行mysql的库存扣减以及增加用户领券记录，这里在redis中也用zset进行存储，最后再发一个延迟消息，去执行到期过期逻辑。
  - 【这里生产者没有选择发送失败重试，而是选择**打印日志并报警，通过日志搜集并重新投递**】



## Redis 的库存预扣减之后，如果 RocketMQ 发送消息失败了，库存是不是就白扣了？怎么兜底？

Redis 作为“临时库存”没问题，但如果消息完全没发出去，你数据库不会扣，Redis 库存是不是就不一致了？

企业级解决方案

```
[用户发起秒杀请求]
            |
            v
[Lua 脚本扣库存 + 校验用户资格]
            |
            v
[写入 Redis pending 标记键]
（key = pending:userId:templateId）
            |
            v
[添加补偿事件到 Redis List]
（key = pending_coupon_mq_list）
            |
            v
[发送 RocketMQ 同步消息]
            |
      +-----+------+
      |            |
   成功         失败 / 异常
      |            |
      v            v
[删除 Redis       [保留 Redis pending 键]
 pending 键]      [补偿事件已在 List 中等待重投]
      |
      v
[消费成功，落库成功，发券完成]
```

```
[定时任务触发]
        |
        v
[从 Redis List 中取出补偿事件]
        |
        v
[判断是否已落库（幂等校验）]
        |
        +------------+
        |            |
     已落库        未落库
        |            |
     丢弃         重试发送 MQ 消息
                     |
         +-----------+----------+
         |                      |
      成功                   失败
         |                      |
 [删除 pending 键]     [retry_count + 1]
                           |
                 [重新入 Redis List]
                    （最多 retry 3 次）
```



- Redis pending 键用于追踪**扣库存后但未成功发券**的状态。
- Redis List 是补偿队列，确保所有异常都能被“兜住”。
- 幂等判断可查询用户是否已发券或数据库是否存在记录。







# 7.数据库表设计

## 券模板表（分库分表）

```sql
CREATE TABLE `t_coupon_template`
(
    `id`               bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID',
    `name`             varchar(256) DEFAULT NULL COMMENT '优惠券名称',
    `shop_number`      bigint(20) DEFAULT NULL COMMENT '店铺编号',
    `source`           tinyint(1) DEFAULT NULL COMMENT '优惠券来源 0：店铺券 1：平台券',
    `target`           tinyint(1) DEFAULT NULL COMMENT '优惠对象 0：商品专属 1：全店通用',
    `goods`            varchar(64)  DEFAULT NULL COMMENT '优惠商品编码',
    `type`             tinyint(1) DEFAULT NULL COMMENT '优惠类型 0：立减券 1：满减券 2：折扣券',
    `valid_start_time` datetime     DEFAULT NULL COMMENT '有效期开始时间',
    `valid_end_time`   datetime     DEFAULT NULL COMMENT '有效期结束时间',
    `stock`            int(11) DEFAULT NULL COMMENT '库存',
    `receive_rule`     json         DEFAULT NULL COMMENT '领取规则',
    `consume_rule`     json         DEFAULT NULL COMMENT '消耗规则',
    `status`           tinyint(1) DEFAULT NULL COMMENT '优惠券状态 0：生效中 1：已结束',
    `create_time`      datetime     DEFAULT NULL COMMENT '创建时间',
    `update_time`      datetime     DEFAULT NULL COMMENT '修改时间',
    `del_flag`         tinyint(1) DEFAULT NULL COMMENT '删除标识 0：未删除 1：已删除',
    PRIMARY KEY (`id`),
    KEY                `idx_shop_number` (`shop_number`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=1810967816300515330 DEFAULT CHARSET=utf8mb4 COMMENT='优惠券模板表';
```

单台 MySQL Server 的写瓶颈大概在 4000-5000/TPS，如果我们的场景业务每秒 TPS 在 1 万，那么就需要至少分两个库



### shop_number字段

用作分片键

### source字段

平台券：平台创建，成本由平台和商家一起承担

商家券：商家自己创建，成本由商家承担

### target，goods字段

goods暂时用的是varchar存储，用分号分割

若商品过多，可能有会有查询效率低的问题，改进：

可以建立 `t_coupon_template_goods` 关联表，并用  (`goods_code`, `coupon_template_id`)做联合索引

```sql
CREATE TABLE `t_coupon_template_goods`
(
    `id`               bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID',
    `coupon_template_id` bigint(20) NOT NULL COMMENT '优惠券模板ID',
    `goods_code`       varchar(64) NOT NULL COMMENT '商品编码',
    `create_time`      datetime DEFAULT NULL COMMENT '创建时间',
    `update_time`      datetime DEFAULT NULL COMMENT '修改时间',
    PRIMARY KEY (`id`),
    UNIQUE KEY `uniq_coupon_goods` (`coupon_template_id`, `goods_code`),
    KEY `idx_goods_code` (`goods_code`) USING BTREE,
    CONSTRAINT `fk_coupon_template` FOREIGN KEY (`coupon_template_id`) REFERENCES `t_coupon_template` (`id`) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='优惠券模板适用商品表';

```

### type，stock，status 字段

type：优惠类型 0：立减券 1：满减券 2：折扣券

stock：券库存

### valid_start_time，valid_end_time 字段

有效时间



## 用户领券记录表

```sql
CREATE TABLE `t_user_coupon` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID',
  `user_id` bigint(20) DEFAULT NULL COMMENT '用户ID',
  `coupon_template_id` bigint(20) DEFAULT NULL COMMENT '优惠券模板ID',
  `receive_time` datetime DEFAULT NULL COMMENT '领取时间',
  `receive_count` int(3) DEFAULT NULL COMMENT '领取次数',
  `valid_start_time` datetime DEFAULT NULL COMMENT '有效期开始时间',
  `valid_end_time` datetime DEFAULT NULL COMMENT '有效期结束时间',
  `use_time` datetime DEFAULT NULL COMMENT '使用时间',
  `source` tinyint(1) DEFAULT NULL COMMENT '券来源 0：领券中心 1：平台发放 2：店铺领取',
  `status` tinyint(1) DEFAULT NULL COMMENT '状态 0：未使用 1：锁定 2：已使用 3：已过期 4：已撤回',
  `create_time` datetime DEFAULT NULL COMMENT '创建时间',
  `update_time` datetime DEFAULT NULL COMMENT '修改时间',
  `del_flag` tinyint(1) DEFAULT NULL COMMENT '删除标识 0：未删除 1：已删除',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_user_id_coupon_template_receive_count` (`user_id`,`coupon_template_id`,`receive_count`) USING BTREE,
  KEY `idx_user_id` (`user_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=1815640588360376337 DEFAULT CHARSET=utf8mb4 COMMENT='用户优惠券表';
```



##  ShardingSphere-JDBC 如何进行 SQL 路由？

ShardingSphere-JDBC 采用 SQL 解析 + 路由规则计算的方式进行 SQL 路由

SELECT * FROM orders WHERE user_id = 123;

- 解析 user_id 作为分片键。
- 计算 user_id % 4 = 3，路由到 db_3.orders_3。
- 执行 SELECT * FROM db_3.orders_3 WHERE user_id = 123;



## 分库分表用商家id分片，那如果用非商家id查询怎么办

- 第一种是创建**路由表**，即使用非分片键和分表键组一个表，先通过非分片键查询到分片键，通过分片键去查询
- 第二种是采用**异构数据源**的方式，将 MySQL 数据库记录同步到 **ES** 或者数仓里，这种查询也可以



# 8.防止重复提交

Redisson 分布式锁的 底层`key-value` 结构

**Key（锁的名称）**：

- `lock:{lockName}`

**Value（锁的持有者信息）**：

- `UUID:ThreadId`（唯一标识客户端和线程的组合）



## key的设置

```java
String lockKey = String.format("no-duplicate-submit:path:%s:currentUserId:%s:md5:%s", getServletPath(), getCurrentUserId(), calcArgsMD5(joinPoint));

```

**固定前缀**no-duplicate-submit

**当前请求的 URL 路径** getServletPath

**获取当前用户** ID  currentUserId

计算请求参数（切点）的 MD5 calcArgsMD5(joinPoint)



# 优惠券预约

吟唱：
在我们项目中，为了提升优惠券秒杀的转化率和用户体验，我们设计了一个**“优惠券预约提醒”模块**。用户可以提前预约即将开始的优惠券，在券快开始的时候收到通知。

这个模块主要支持：

- 用户预约未来优惠券的提醒时间（如提前 5 分钟、1 小时等）
- 支持 **多个提醒时间点（位图编码）**，支持更新/取消
- 到点后通过 **延迟消息** 自动触发提醒推送
- 用户可以查看、取消自己的预约记录

## 详细业务

#### **✅ 1.** **预约信息存储结构**

- 用户预约信息保存在一张表中，一条记录可能包含多个时间点的预约，使用 **BitMap 位图编码** 表示提醒时间 + 提醒类型（短信、站内信等），提升结构紧凑性。



#### **✅ 2.** **创建提醒流程**

- 提交预约时会校验优惠券是否存在、是否未开始
- 若已预约，会按位合并提醒时间；否则新建记录
- 最后构造一个 **延迟消息（RocketMQ 延迟消息）**，到点时触发提醒



#### **✅ 3.** **取消提醒流程**

- 用户取消某个时间点的提醒时，会按位 XOR 清除
- 若全部提醒时间被取消，则直接删除记录
- 同时将取消信息哈希后写入一个 **布隆过滤器（Redis Bloom）**，用于后续判断



#### **✅ 4.** **判断是否取消**

- 推送任务在执行前，先通过布隆过滤器判断用户是否已取消提醒
- 若命中，再去 DB 做一次位图判断，避免布隆误判



#### **✅ 5.** **预约信息查询**

- 查询用户预约信息时，先查 Redis 缓存，未命中时查库并写入缓存（TTL 1分钟）
- 避免高频访问 DB，保证页面打开速度



## 流程图

### **优惠券预约提醒业务流程图**

```
【预约提醒入口：用户点击“预约提醒”按钮】
        |
        v
[1] 校验优惠券是否存在，是否已开始
        |
        v
[2] 查询是否已有预约记录
        |
   +----+-----------------------------+
   |                                  |
[没有记录]                     [已有记录]
   |                                  |
[构造预约记录]                [计算提醒时间 BitMap]
[写入 DB]                      |
                                v
                     [该时间点已存在提醒？]
                                |
                     +----------+----------+
                     |                     |
                [是]抛异常         [否] 合并 BitMap，更新记录
                                             |
                                             v
        [3] 构造延迟提醒消息对象（RocketMQ 延迟消息）
                                             |
                                             v
        [4] 发送消息（提醒用户到点来领券）
```

- calculateBitMap 
  - 根据**remindTime**和**type**计算相应的 bitmap 使用 long 类型的字段来存储提醒信息，总计64个比特位
    - 假设用户预约了**类型为 0** 的提醒
      - 该类型的提醒时间存储在**第1到第12个比特位**，**每个比特位对应一个5分钟**的时间间隔
        - 第10分钟和第45分钟的节点，第2位和第9位的比特被置为 1
    - 假设用户预约了类型为 1 的提醒
      - 其信息存储在第13到第24个比特位
        - 如果用户预约了15分钟和50分钟的节点
  - calculateBitMap 的计算方法
    - 首先通过 type * NEXT_TYPE_BITS 计算提醒类型的偏移量
      - 例如，type = 0 时，偏移量为 0，表示从第0位开始；type = 1 时，偏移量为 12，表示从第12位开始存储信息
    - 接下来，Math.max(0, remindTime / TIME_INTERVAL - 1) 是为了确保提醒时间在有效范围内
      - 用 Math.max 的目的是防止 remindTime / TIME_INTERVAL - 1 小于 0，这通常会发生在 remindTime 小于5分钟的情况下
    - 如果 type = 1，提醒时间为15分钟，带入公式计算
      - 1 * NEXT_TYPE_BITS + Math.max(0, 15 / 5 - 1) = 14
        - 因此 1L 向左偏移14位



### **查看用户预约列表流程（listCouponRemind）**

```
【用户访问“我的预约”页面】
        |
        v
[1] 查询 Redis 缓存
        |
   +----+---------------------+
   |                          |
[缓存命中]             [缓存未命中]
   |                          |
直接返回             查询 DB 预约记录
                              |
                        查询券模板信息
                              |
                    合并组装返回数据
                              |
                        写入 Redis 缓存（1分钟）
```



### **用户取消预约流程（cancelCouponRemind）**

```
【用户点击取消预约提醒】
        |
        v
[1] 校验券是否存在、是否已开始
        |
        v
[2] 查询该用户对应的预约记录
        |
        v
[3] 根据传入的提醒时间点计算 BitMap
        |
        v
[4] 判断该时间点是否预约过
        |
        v
[5] 更新 BitMap：
    |
    +—— 若新 BitMap 为 0 → 删除记录
    |
    +—— 否则 → 更新 DB 中信息字段
        |
        v
[6] 添加记录到布隆过滤器中（cancelRemindBloomFilter）
        |
        v
[7] 删除缓存（等待下一次查询时延迟重建）
```



### **判断是否取消提醒（isCancelRemind）**

```
【系统准备推送预约提醒时】
        |
        v
[1] 根据用户 + 券 + 时间 + 类型，计算 hash
        |
        v
[2] 判断是否存在于 cancelRemindBloomFilter 中
        |
   +----+-----------------------------+
   |                                  |
[不存在]                        [存在]
   |                                  |
说明用户未取消              |   进一步查 DB
                            v
                  [DB 没数据 or bitMap 不匹配]
                            |
                      判断为取消
```



## 问题

### **你用位图存储用户多个提醒时间点，有什么优势？是否考虑过多行记录方案？**

我们用位图（BitMap）来记录多个提醒时间点是为了提升**存储效率**和**操作性能**：

- **一个用户一条记录**，避免了多条记录的插入和更新压力
- 多个提醒时间可以通过按位与/或/XOR 操作高效合并或取消
- MySQL 存储空间节省，同时支持乐观锁进行并发更新控制

我们也考虑过一行一提醒的方案，但那种方式在查询、更新和幂等校验上的开销都更高，位图更适合我们这种“提醒时间集合有限且固定”的场景。



### **取消提醒时用了布隆过滤器，为什么不直接查 Redis / 数据库判断？**

取消提醒之后我们把哈希值写入布隆过滤器，是为了优化 **“提醒触发”阶段的大量访问判断**：

- 延迟消息到点后可能大规模并发触发，这时候我们首先通过布隆过滤器快速判断是否已取消
- 相比直接查 DB，布隆过滤器能以纳秒级性能响应，大幅降低系统访问压力
- 对于布隆过滤器的误判，我们后续仍有 DB 的二次校验保证准确性

也就是说，布隆过滤器是“高性能预判”，DB 是“准确最终判断”，两者配合达成性能与一致性的平衡。



### **你 Redis 中缓存了预约提醒列表，怎么保证它和数据库是一致的？有没有考虑并发修改问题？**

我们使用的是 **“更新数据库后删除缓存”** 的策略：

- 每次新增或取消预约后，我们更新数据库，并删除对应用户的缓存
- 下次访问列表时，由缓存 miss 驱动重新从数据库加载，保证数据准确性

针对并发修改的问题，我们做了两点防护：

1. **乐观锁更新（使用 where + old bitmap 匹配）**
2. **缓存 key 精准删除（按 userId 精确删除提醒缓存）**



### **你为什么要使用布隆过滤器？这个布隆过滤器有没有“失效机制”？会不会一直变大？**

我们使用布隆过滤器来优化“是否取消提醒”的判断逻辑，主要用于性能优化。

布隆过滤器特点是：

- 空间占用极低（比如 100w 数据，误判率千分之一，占用不到几 MB）
- 写入成本低，读取极快
- 但缺点是：**无法删除元素、不可自动过期、会有误判**

我们的应对策略：

- 使用 Redisson 提供的可复用布隆过滤器，每次应用重启时可重建
- 由于取消提醒属于长期有效信息，不需要过期
- 如果日后量太大，可定期重建布隆过滤器（参考 Redis 冷启动时方案）



# 锁定/核销/退还优惠券

- 优惠券状态
  - 兑换优惠券（未使用）
    - 优惠券被领取到用户账户中，初始状态为 未使用
  - 订单结算（锁定中）
    - 用户在订单中使用优惠券时，优惠券状态应变更为 锁定中
      - 此时优惠券不可被其他订单再次使用，直到订单完成或取消
  - 支付成功（已使用）
    - 用户支付订单后，优惠券状态变更为 已使用
      - 表示优惠券使用成功，不可再被使用
  - 订单退款（未使用）
    - 如果订单取消或发生退款，优惠券状态回退至 未使用
      - 重新回到用户账户中，可被再次使用

```
          [UNUSED]
              |
         createPaymentRecord
              ↓
          [LOCKING]
           /      \
processRefund   processPayment
     ↓               ↓
 [UNUSED]          [USED]
                        ↓
                  processRefund
                        ↓
                   [REFUNDED]
```



## 流程图

### **用户下单 → 创建结算记录（锁券）**

```
[用户提交订单，选择使用优惠券]
        |
        v
【1】尝试获取优惠券锁（Redisson 分布式锁）
        |
        v
【2】校验结算记录是否已存在（未使用/锁定）
        |
        v
【3】校验优惠券是否存在 + 未过期 + 状态为未使用
        |
        v
【4】查询优惠券模板 + 解析消费规则（店铺、商品、满减等）
        |
        v
【5】验证金额、计算折扣金额（最大抵扣 / 折扣率）
        |
        v
【6】校验用户期望支付金额是否匹配
        |
        v
【7】开启事务：
        ├─ 插入结算记录（状态：锁定）
        └─ 更新用户优惠券状态 → LOCKING
        |
        v
【8】删除 ZSet 中的可用优惠券缓存（避免重复领取）
        |
        v
释放锁，创建成功
```



### **用户支付成功 → 核销优惠券**

```
[订单支付成功]
        |
        v
【1】尝试获取锁（按券 ID 加锁）
        |
        v
【2】开启事务：
        ├─ 更新结算记录状态：LOCKING → USED
        └─ 更新用户券状态：LOCKING → USED
        |
        v
释放锁，核销成功
```



### **用户退款成功 → 退还优惠券**

```
[订单取消或退款]
        |
        v
【1】尝试获取锁（按券 ID 加锁）
        |
        v
【2】开启事务：
        ├─ 更新结算记录状态：USED → REFUNDED
        └─ 更新用户券状态：USED → UNUSED
        |
        v
【3】重新放回 Redis ZSet 缓存（用户可再次使用）
        |
        v
释放锁，退还成功
```



# 结算业务

## 流程图

```
[用户提交订单结算页]
         |
         v
【1】查询用户 Redis 中已领取的可用优惠券（ZSet）
         |
         v
【2】批量构造券模板 Redis Key，使用 pipelined 批量获取券模板信息（Hash）
         |
         v
【3】按 goods 字段是否为空，将模板拆分为两类：
     ├─ 商品无绑定券（goodsEmptyList）
     └─ 商品绑定券（goodsNotEmptyList）
         |
         v
【4】遍历券模板，执行优惠券可用性判断（两类分开处理）：

       ┌───────────────┬─────────────────────────────────────────────────
       │   商品无绑定券（店铺券）           │ 商品绑定券（商品专属券）         │
       └───────────────┴────────────────────────────────────────────────
             ↓                          ↓
   读取 consumeRule 字段解析规则      关联商品编号 → 判断门槛金额

   优惠券类型判断逻辑一致：立减 / 满减 / 折扣
             ↓                          ↓
   是否满足门槛 ➝ 计算 couponAmount（可抵扣金额）
             ↓
  ┌───────────────────────────────────
  │ 加入 available / notAvailable 列表 │
  └───────────────────────────────────

【5】将所有可用券按优惠力度（couponAmount）降序排序
         |
         v
【6】封装为响应对象：
  - availableCouponList
  - notAvailableCouponList
         |
         v
【7】返回前端，供用户选择
```

